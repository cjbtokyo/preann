#+TITLE:       Entrenamiento por refuerzo de redes neuronales mediante algoritmos gen\'eticos
#+AUTHOR:      Jorge Tim\'on Morillo-Velarde
#+EMAIL:       jtimonmv@gmail.com
#+KEYWORDS:    Redes neuronales, algoritmos gen\'eticos, redes neuronales evolutivas, aprendizaje por refuerzo, CUDA, entornos artificiales, juegos multi-agente.
#+LANGUAGE:    es
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[margin=2.5cm,includefoot]{geometry}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{pict2e}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{chngcntr}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{import}
#+LATEX_HEADER: \hypersetup{
#+LATEX_HEADER:     colorlinks,%
#+LATEX_HEADER:     citecolor=green,%
#+LATEX_HEADER:     filecolor=black,%
#+LATEX_HEADER:     linkcolor=blue,%
#+LATEX_HEADER:     urlcolor=blue
#+LATEX_HEADER: }
#+OPTIONS:     toc:nil H:5
#+BIND: org-export-latex-title-command ""

# definiciones propias
#+begin_latex

\setcounter{secnumdepth}{5}
\counterwithin{figure}{section}
\setcounter{tocdepth}{5}

\newcommand{\mail}[1][jtimonmv@gmail.com]{%
     \href{mailto:#1} {#1}
}

\newcommand{\definicion}[1]{%
	\textbullet \bfseries{ #1 :}
}

\newenvironment{listaDefiniciones}%
%ordenes al inicio
{
\begin{list}{}%
     {  \setlength{\itemsep}{0.5ex}
	\setlength{\parsep}{0.5ex}
	\setlength{\partopsep}{0.5ex}
	\setlength{\topsep}{\dimexpr 2\itemsep}
	\setlength{\listparindent}{\dimexpr \parindent}
	\renewcommand*{\makelabel}[1]{\definicion{##1}}
	}
}
%ordenes al final
{
\end{list}
}%

#+end_latex

# Título, abstract e índice
#+begin_latex


\begin{titlepage}

\title{Entrenamiento por refuerzo de redes neuronales mediante algoritmos gen\'eticos}
\newline
\newline
\newline

\author{
\\ Autor:\\
\\ Jorge Tim\'on Morillo-Velarde \\ \mail
\\ \\ \\ \\
\\ Tutores del proyecto:\\ 
\\ Rosa M. P\'erez Utrero \\ \mail[rosapere@unex.es]
\\ 
\\ Juan A. G\'omez Pulido \\ \mail[jangomez@unex.es]
\\ \\ \\ \\
}

\date{\today}
\maketitle

\newpage
\begin{abstract}

En este trabajo se estudia un m\'etodo alternativo para el entrenamiento de redes neuronales con conexi\'on hacia delante. Se utiliza un algoritmo gen\'etico para ajustar los pesos de la red neuronal. Se eval\'ua el uso de diferentes tipos de neuronas (con salida real o binaria) para comparar sus rendimientos utilizando diferentes implementaciones paralelas (para el coprocesador XMM y para la arquitectura CUDA). Se prueban variaciones de los operadores gen\'eticos y se mide su efectividad en el entrenamiento. Se enfrenta el algoritmo a diferentes tipos de problemas de aprendizaje por refuerzo y se medita sobre la idoneidad del mismo para cada problema.
\\

\textbf{Palabras clave:} Redes neuronales, algoritmos gen\'eticos, redes neuronales evolutivas, aprendizaje por refuerzo, CUDA, entornos artificiales, juegos multi-agente.

\end{abstract}

\newpage

\tableofcontents

\newpage
#+end_latex

* Introducci\'on
#+LaTeX: \label{intro}

 El /aprendizaje autom\'atico/ es una rama de la inteligencia artificial que trata de construir sistemas inform\'aticos que optimicen un criterio de rendimiento utilizando datos o experiencia previa. Dentro del aprendizaje autom\'atico, las t\'ecnicas se clasifican en base a su entrenamiento como supervisado o no supervisado. En el primero, al sistema se le suministran ejemplos de entradas con sus correspondientes salidas deseadas. En el entrenamiento no supervisado, no se tienen a priori ejemplos de c\'omo deber\'ia comportarse el sistema. El aprendizaje por refuerzo es un caso especial de aprendizaje supervisado en que la salida deseada exacta es desconocida. Se basa s\'olo en informaci\'on sobre si la salida actual es correcta o no. Al agente que se quiere que aprenda se le provee informaci\'on sobre lo bien o lo mal que est\'a actuando. Esta se\~nal de recompensa puede serle indicada bien cada vez que el agente act\'ua, bien al final de una prueba completa durante la que realiza varias acciones.

 Los algoritmos que tienen su origen en la observaci\'on de la naturaleza se denominan bio-inspirados. Entre ellos se encuentran las redes neuronales y los algoritmos gen\'eticos. 

 Las redes neuronales son modelos que intentan reproducir el comportamiento del cerebro humano [Hilera y Mart\'inez, 1995]. Una red neuronal consiste en un conjunto de elementos de procesamiento, llamados neuronas, los cuales se conectan entre s\'i [Koehn, 1994]. Las conexiones entre las neuronas tienen pesos asociados cuyos valores determinar\'an el comportamiento de la red. Existen algoritmos para determinar el valor de los pesos de una red mediante un entrenamiento supervisado, cabe destacar el de retro-propagaci\'on del error.

 Los algoritmos evolutivos, dentro de los cuales los algoritmos gen\'eticos son los m\'as conocidos, son una familia de modelos computacionales inspirados en la evoluci\'on y la supervivencia del m\'as apto [B\"ach, et. al., 1991; \"Omer, 1995; Whitley, 2001]. Se utilizan fundamentalmente en la resoluci\'on de problemas de b\'usqueda y de optimizaci\'on [Holland, 1975]. Buscan una soluci\'on del problema reproduciendo gen\'eticamente una poblaci\'on de individuos a lo largo de una serie de generaciones [Koza, 1997]. El aprendizaje es formulado como un problema de optimizaci\'on, en el que cada individuo de la poblaci\'on es una posible soluci\'on.

 Dada una topolog\'ia de red fija, el entrenamiento de una red neuronal puede ser visto como un proceso de optimizaci\'on cuyo objetivo es encontrar un conjunto de pesos que minimice el error que produce la red sobre el conjunto de ejemplos en el entrenamiento supervisado, o que maximice la recompensa en el aprendizaje por refuerzo.

 En nuestro caso, el agente utilizar\'a una red neuronal para decidir sus acciones (salida de la red) a partir de los datos que pueda recoger de su entorno (entrada a la red). Se utiliza un algoritmo gen\'etico para decidir los pesos adecuados para la red, utilizando una poblaci\'on de agentes con redes diferentes. Se utiliza la recompensa acumulada por el individuo en una o varias pruebas para medir su adaptaci\'on al medio. Se utilizan estas medidas y la poblaci\'on actual para construir la siguiente generaci\'on. Cuando alg\'un individuo demuestra estar lo suficientemente adaptado al medio para cumplir con las expectativas del entrenamiento (o cuando se supera un l\'imite prefijado de iteraciones), \'este finaliza.

 En todo este proceso, El algoritmo que m\'as se ejecuta es el que calcula la salida de la red a partir de la entrada. Este algoritmo se puede llamar varias veces por cada prueba. Adem\'as, las pruebas pueden repetirse varias veces por individuo y generaci\'on para disminuir el ruido producido por los factores aleatorios que pueda haber en las pruebas. Por ello, esta funci\'on se ha optimizado mediante su paralelizaci\'on en dos arquitecturas ampliamente extendidas y econ\'omicas: el coprocesador XMM, presente en todos los PCs de reciente fabricaci\'on y la arquitectura CUDA[Nota al pie: CUDA forma parte de lo que se conoce como GPGPU, que consiste en utilizar unidades de procesamiento gr\'afico (GPUs) para c\'alculos generales que no tienen por qu\'e ser gr\'aficos], compatible con la mayor\'ia de tarjetas gr\'aficas NVIDIA a partir de la serie 8000. Adem\'as, para incrementar a\'un m\'as el rendimiento, se estudia la viabilidad de entrenar redes con una versi\'on m\'inima de neurona con activaci\'on de tipo escal\'on y con pesos con tama\~no de un byte (en la secci\'on \ref{disenoParal} se describe con m\'as detalle). Llamaremos a las redes que utilizan estas estructuras redes discretas.

 Los problemas en los que aplicamos nuestro desarrollo, aunque no son realistas, se consideran interesantes para la rob\'otica y/o para la inteligencia artificial. Los tipos de problemas tienen que ver con la clasificaci\'on, los juegos considerados como deportes mentales, el control autom\'atico, la toma de decisiones en tiempo real y la colaboraci\'on de m\'ultiples agentes en tiempo real; pudiendo estar relacionados estos \'ultimos con la
[[http://es.wikipedia.org/wiki/Vida_artificial][vida artificial]]. En la mayor\'ia de los problemas, el agente se enfrenta a pruebas gen\'ericas que pueden tener factores aleatorios y/o agentes directamente programados. En algunos problemas, sin embargo, los agentes de la poblaci\'on pueden enfrentarse entre ellos para obtener una valoraci\'on.

 En el presente documento (que contiene la documentaci\'on asociada al proyecto fin de carrera titulado \flqq Entrenamiento por refuerzo de redes neuronales mediante algoritmos gen\'eticos\frqq, desarrollado por Jorge Tim\'on Morillo-Velarde para la consecuci\'on del t\'itulo de ingenier\'ia inform\'atica), primero comentaremos los fundamentos te\'oricos precisos para su comprensi\'on y su correcta ubicaci\'on dentro del dominio de la neuro-evoluci\'on, diferenci\'andolo de otros desarrollos en \'este \'area. Despu\'es, justificaremos las principales decisiones tomadas durante el desarrollo y explicaremos en detalle algunas partes de su implementaci\'on. Los rendimientos obtenidos con las diferentes implementaciones paralelas y opciones en el algortimo genético se muestran en el capítulo \ref{rendimiento}.En el cap\'itulo \ref{experimentacion}, se describen los experimentos realizados y se justifica la elecci\'on de los mismos. El cap\'itulo de resultados de aprendizaje \ref{aprendizaje} expone los datos emp\'iricos recogidos en los experimentos y razona unas someras conclusiones que luego se completan en el cap\'itulo \ref{conclusiones}.

\newpage
* TODO Base te\'orica
#+LaTeX: \label{baseTeorica}

Tanto las redes neuronales como los algoritmos gen\'eticos est\'an inspirados en la naturaleza y han sido utilizados desde largo tiempo atr\'as. Las redes neuronales est\'an inspiradas en el funcionamiento del cerebro, como un sistema de procesamiento de informaci\'on distribuido. Por su parte, los algoritmos gen\'eticos se basan en la teor\'ia de la evoluci\'on de Darwin, por la que la evoluci\'on se produce a trav\'es de dos principios b\'asicos: los individuos que no se adaptan suficientemente al medio perecen, mientras que los que s\'i lo hacen transmiten sus genes con cierta variabilidad. Esta variabilidad puede proceder de dos fuentes: la cruza de genes entre individuos \'o la mutaci\'on directa de genes.

 La combinaci\'on de estas dos t\'ecnicas es algo relativamente reciente. Algunos - principalmente anglosajones - han coincidido en llamar a esta s\'intesis [[http://en.wikipedia.org/wiki/Neuroevolution][neuro-evoluci\'on]], otros se refieren a ella como [[http://laral.istc.cnr.it/nolfi/papers/HBTNN-A.pdf][evoluci\'on de redes neuronales artificiales]], pero - en general - la mayor\'ia de los que la usan recurren a nombres que definen con m\'as precisi\'on la t\'ecnica concreta que utilizan; dadas las m\'ultiples posibilidades para combinar ambos m\'etodos. Aceptaremos el t\'ermino neuro-evoluci\'on para el resto del texto, aunque sin renunciar a los otros t\'erminos que hayan podido ser utilizados como redes neuronales evolutivas.

 A continuaci\'on explicaremos m\'as detalladamente las bases te\'oricas de las tres t\'ecnicas: redes neuronales, algoritmos gen\'eticos y neuro-evoluci\'on. Nos centraremos principalmente en los algoritmos y estructuras que m\'as se asemejan a los implementamos en nuestra librer\'ia.

** Redes neuronales
#+LaTeX: \label{basTeoRedes}

Las redes neuronales constan de un conjunto de elementos de procesamiento - conocidos como nodos o neuronas - interconectados entre s\'i. Pueden ser descritas mediante un grafo dirigido en el que cada neurona  \(i\) usa una funci\'on de activaci\'on de la forma:

\begin{equation}\label{eqSalidaNeu}
  y_i=f_i(\sum_{j=1}^n (w_{ij} \cdot x_j - \theta_i)).
\end{equation}

donde \(y_i\) es la salida de la neurona \(i\), \(x_j\) es la entrada n\'umero \(j\) a la misma, \(w_{ij}\) es el peso de la conexi\'on entre los nodos \(i\) y \(j\), \(\theta_i\) es el umbral de activaci\'on (o Bias) y \(f_i\) es una funci\'on que puede ser, o no, lineal.

#+CAPTION:    Red neuronal \emph{feed-forward}.
#+LABEL:      figFeedForward
#+ATTR_LaTeX: trim= 0.5cm 22cm 10cm 0cm, clip, width=15cm
[[./img/feed-forward.jpg]]

 Las redes neuronales artificiales pueden clasificarse como \emph{feed-forward} (con propagaci\'on hacia delante) o recurrentes dependiendo de su conectividad. Una red es \emph{feed-forward} (figura \ref{figFeedForward}) si existe un m\'etodo de numeraci\'on de las neuronas que cumpla que no existan conexiones desde un nodo hacia otro nodo con un n\'umero m\'as peque\~no que el de nodo de origen. Una red es recurrente (figura \ref{figRecurrente}) si no existe un m\'etodo de numeraci\'on que cumpla tal condici\'on. Para simplificar nuestro trabajo, nos centraremos en las redes \emph{feed-forward}.

#+CAPTION:    Red neuronal recurrente.
#+LABEL:      figRecurrente
#+ATTR_LaTeX: scale=0.35
[[./img/recurrente.jpg]]

 El aprendizaje de las redes neuronales se consigue habitualmente usando ejemplos: suelen tener un entrenamiento supervisado. Se basa en la comparaci\'on directa entre la salida de la red y la salida correcta o deseada. Normalmente se formula el entrenamiento como la minimizaci\'on de una funci\'on de error como el sumatorio del cuadrado del error de la salida respecto de la salida deseada para todos los datos disponibles (que constan de pares de entradas con sus correspondientes salidas deseadas). Un algoritmo de optimizaci\'on basado en el descenso del gradiente como la regla delta generalizada (tambi\'en conocido como algoritmo backpropagation) puede ser usado despu\'es iterativamente para ajustar los pesos y as\'i minimizar el error.

 En nuestro caso, utilizamos aprendizaje por refuerzo y no necesitamos una colecci\'on de ejemplos (aunque se podr\'ia utilizar para calcular el refuerzo). Los pesos los ajustar\'a un algoritmo gen\'etico. La estructura de la red se definir\'a de forma previa para cada problema y s\'olo evolucionar\'an los pesos (y umbrales).

** Algoritmos gen\'eticos
#+LaTeX: \label{basTeoGenet}

Los algoritmos gen\'eticos son m\'etodos sistem\'aticos para la resoluci\'on de problemas de b\'usqueda y optimizaci\'on que aplican a \'estos los principios de la evoluci\'on biol\'ogica: selecci\'on basada en la poblaci\'on, reproducci\'on sexual y mutaci\'on.

 Los algoritmos gen\'eticos son m\'etodos de optimizaci\'on, que tratan de resolver el conjunto de problemas formulados como: hallar (xi,...,xn) tales que F(xi,...,xn) sea m\'aximo. En un algoritmo gen\'etico, tras parametrizar el problema en una serie de variables (xi,...,xn), se codifican en un cromosoma. Todos los operadores utilizados por un algoritmo gen\'etico se aplicar\'an sobre estos cromosomas, o sobre poblaciones de ellos. En el algoritmo gen\'etico va impl\'icito el m\'etodo para resolver el problema; son s\'olo par\'ametros de tal m\'etodo los que est\'an codificados - a diferencia de otros algoritmos evolutivos como la programaci\'on gen\'etica. Hay que tener en cuenta que un algoritmo gen\'etico es independiente del problema, lo cual lo hace un algoritmo robusto, por ser \'util para cualquier problema, pero a la vez d\'ebil, pues no est\'a especializado en ninguno.

 Las soluciones codificadas en un cromosoma compiten para ver cu\'al constituye la mejor soluci\'on (aunque no necesariamente la mejor de todas las soluciones posibles). El ambiente, constituido por las otras camaradas soluciones, ejercer\'a una presi\'on selectiva sobre la poblaci\'on, de forma que s\'olo los mejor adaptados (aquellos que resuelvan mejor el problema) sobrevivan o leguen su material gen\'etico a las siguientes generaciones, igual que en la evoluci\'on de las especies. La diversidad gen\'etica se introduce mediante mutaciones y reproducci\'on sexual. En la Naturaleza lo \'unico que hay que optimizar es la supervivencia, y eso significa a su vez maximizar diversos factores y minimizar otros. Un algoritmo gen\'etico, sin embargo, se usar\'a para optimizar habitualmente para optimizar s\'olo una funci\'on, no diversas funciones relacionadas entre s\'i simult\'aneamente. Este tipo de optimizaci\'on, denominada optimizaci\'on multimodal, tambi\'en se suele abordar con un algoritmo gen\'etico especializado.

 Por lo tanto, un algoritmo gen\'etico consiste en lo siguiente: hallar de qu\'e par\'ametros depende el problema, codificarlos en un cromosoma, y se aplican los m\'etodos de la evoluci\'on: selecci\'on y reproducci\'on sexual con intercambio de informaci\'on y alteraciones que generan diversidad. En las siguientes secciones se ver\'an cada uno de los aspectos de un algoritmo gen\'etico.

 Mediante los operadores de selecci\'on, se eligen los individuos que ser\'an progenitores de la siguiente generaci\'on (o directamente formar\'an parte de ella). Con los operadores de cruza, se generan nuevos individuos mezclando los cromosomas de varios individuos (normalmente, dos). Por \'ultimo, los operadores de mutaci\'on a\~naden cambios aleatorios a los individuos. La funci\'on de fitness nos da una aproximaci\'on de la adaptaci\'on del individuo al medio y \'esta es utilizada por los operadores de selecci\'on.

 En nuestro caso, el cromosoma de cada individuo lo forman los pesos de la red que utiliza ese individuo. Para calcular el fitness del individuo, se construir\'a la red con los pesos del cromosoma y se realizar\'an varias pruebas (para reducir el ruido generado por los posibles factores aleatorios de \'estas) sobre el individuo, sumando las recompensas de todas y obteniendo el citado fitness.

*** Algoritmo genético estándar y variaciones
#+LaTeX: \label{basTeoGenetEstan}

*** Operadores de selección
#+LaTeX: \label{basTeoGenetSel}

*** Operadores de cruza
#+LaTeX: \label{basTeoGenetCruz}

** Neuro-evoluci\'on
#+LaTeX: \label{basTeoNeuro}

 La evoluci\'on se ha aplicado las redes neuronales artificiales en tres niveles muy diferentes: a los pesos de las conexiones, la arquitectura de la red y a las reglas de aprendizaje. La evoluci\'on de los pesos de las conexiones introduce una aproximaci\'on global y adaptable al entrenamiento, especialmente para el aprendizaje por refuerzo o para el entrenamiento de redes recursivas, donde los m\'etodos basados en el gradiente experimentan grandes dificultades. La evoluci\'on de las arquitecturas permite a las redes neuronales adaptar su topolog\'ia a diferentes problemas sin intervenci\'on humana y con esto se consigue un dise\~no autom\'atico de redes neuronales, dado que tanto la arquitectura como los pesos pueden ser evolucionados. La evoluci\'on de las reglas de aprendizaje puede ser considerada como un proceso de \textquotedblleft aprender a aprender\textquotedblright en redes neuronales donde la adaptaci\'on de las reglas de aprendizaje se consigue mediante la evoluci\'on. Tambi\'en puede ser contemplada como un proceso de descubrimiento autom\'atico de nuevas reglas de aprendizaje. Nos centraremos en la evoluci\'on de los pesos de las conexiones, por ser la evoluci\'on que utilizaremos.

 La evoluci\'on de los pesos de las conexiones se puede realizar en el aprendizaje supervisado (con ejemplos) definiendo la funci\'on de fitness como el error global obtenido por la red (invirtiendo el signo), comparando las salidas de la red y la salida deseada para cada ejemplo. Tambi\'en puede utilizar para el aprendizaje por refuerzo definiendo una funci\'on de fitness distinta.

 En general, los pasos a seguir son dos: decidir la codificaci\'on de los pesos de las conexiones (si se har\'a mediante cadenas binarias o no) y la ejecuci\'on del algoritmo gen\'etico propiamente dicho. Para el primer paso, las opciones m\'as extendidas son la representaci\'on binaria y la representaci\'on con n\'umeros reales.

   El algoritmo gen\'etico can\'onico siempre usa cadenas de bits para codificar las diferentes soluciones. Por ello, algunos trabajos tempranos de evoluci\'on de los pesos de las conexiones siguen esta aproximaci\'on \cite[Yao99]{Yao99}. Las ventajas son la f\'acil aplicaci\'on de los operadores gen\'eticos y su posible implementaci\'on digital. Habr\'ia que elegir la representaci\'on de los n\'umeros reales. Aqu\'i hay un compromiso para la precisi\'on con que se quieran representar los n\'umeros reales. Si se usan muy pocos bits para representar cada conexi\'on, el entrenamiento puede fallar porque algunas combinaciones de pesos no se pueden aproximar con suficiente precisi\'on por valores discretos. Por otra parte, si se usan demasiados bits, los cromosomas que representen a redes neuronales grandes se volver\'an demasiado largos y la evoluci\'on en proceso resultar\'a muy ineficiente.

 Por su parte, en la representaci\'on con n\'umeros reales, los cromosomas se codifican como vectores de n\'umeros reales con tantos elementos como conexiones. Los operadores gen\'eticos no se pueden aplicar directamente sobre los bits y han de ser dise\~nados de nuevo. Esto puede ser una ventaja, pues, por ejemplo, el operador de mutaci\'on podr\'ia tener una distribuci\'on gaussiana (u otra funci\'on) en lugar de mutar un bit cualquiera sin tener en cuenta su peso en la construcci\'on del n\'umero.

\begin{figure}[t]
\begin{minipage}{0.45\textwidth}
    \includegraphics [width=7.20cm]{./img/grafo1.jpg}
  \caption {Red neuronal y su codificaci\'on binaria (asumiendo que se usan 4 bits para representar cada n\'umero real).}\label{figGrafo1}
\end{minipage}
\begin{minipage}{0.10\textwidth}
\hfill
\end{minipage}
\begin{minipage}{0.45\textwidth}
    \includegraphics [width=7.20cm]{./img/grafo2.jpg}
  \caption{Red equivalente con codificaci\'on alternativa.}\label{figGrafo2}
\end{minipage}
\end{figure}

 Uno de los problemas a los que se enfrenta la evoluci\'on de redes neuronales es el problema de la permutaci\'on. Es causado por el mapeado "muchos-a-uno" desde la representaci\'on en el cromosoma a la red que es construida. Con dos cromosomas distintos se pueden generar redes equivalentes como se muestra en las figuras \ref{figGrafo1} y \ref{figGrafo2}. Se puede solucionar dando m\'as importancia al operador de mutaci\'on que al de cruza (que es el que sufre con este problema) o con otros m\'etodos matem\'aticos \cite[Gomez, Miikkulainen 2003]{GomezMiikkulainen2003}. 

\newpage
* TODO [0/4] An\'alisis del problema
#+LaTeX: \label{analisis}
** TODO Fortalezas y deficiencias
#+LaTeX: \label{anaFortYDeb}

 Tanto las redes neuronales como los algoritmos gen\'eticos tienen fortalezas que nuestro m\'etodo aprovecha y debilidades que se pueden, en parte, minimizar por la combinaci\'on de ambos m\'etodos.

*** Redes neuronales
#+LaTeX: \label{anaFortYDebRedes}

 Las redes neuronales con conexi\'on hacia delante en general son un importante m\'etodo de aproximaci\'on de funciones [Kim, 1992]. El perceptr\'on multicapa es un tipo de red neuronal con conexiones hacia delante. La topolog\'ia de un perceptr\'on multicapa esta definida por un conjunto de capas ocultas, una capa de entrada y una de salida. No existen restricciones sobre la funci\'on de activaci\'on aunque en general se suelen utilizar funciones sigmoideas. Existen demostraciones te\'oricas [Funahashi, 1989] de que un perceptr\'on multicapa cuya funci\'on de activaci\'on sea no constante, acotada y mon\'otona creciente es un aproximador universal de funciones. En [Hornik et alt, 1989] se llega a un resultado similar utilizando funciones de activaci\'on sigmoideas, no necesariamente continuas. Esto es un punto muy fuerte de las redes neuronales. 

 Adem\'as, constituyen buena una herramienta para la construcci\'on de agentes pues s\'olo hay que codificar las entradas y las salidas de la red como las del agente y el tiempo de ejecuci\'on de la red s\'olo depende de la topolog\'ia de \'esta (para una topolog\'ia dada, es constante).

 Algunas deficiencias del algoritmo back-propagation son su baja adaptabilidad, la alta dependencia de los par\'ametros del algoritmo, el estancamiento en m\'inimos locales, la posibilidad de par\'alisis y la alta dependencia de las condiciones iniciales.
\begin{listaDefiniciones}

 \item [Adaptabilidad] El algoritmo tiene como premisa la utilizaci\'on de una funci\'on de activaci\'on derivable [Walker, 1995]. Al hacer uso de la derivada de la funci\'on de activaci\'on, es condici\'on necesaria para la aplicaci\'on del algoritmo que la misma sea continua y derivable en todo el dominio de aplicaci\'on [Wilson, 1994]. Esto impide la utilizaci\'on del m\'etodo en otras topolog\'ias donde la funci\'on de activaci\'on presenta discontinuidades.

 Este problema suele encontrarse en varios m\'etodos de entrenamiento, los cuales son desarrollados para una determinada topolog\'ia y sus resultados, en general, no son extensibles directamente a otras topolog\'ias. Es necesario adaptar los m\'etodos para aplicarlos a otras topolog\'ias.

\item [Dependencia de par\'ametros del algoritmo] Los algoritmos de gradiente descendente hacen uso de una tasa de aprendizaje que idealmente deber\'ia ser infinitesimal. De esta manera, mediante peque\~nos ajustes de los pesos sin\'apticos el algoritmo converge hacia un m\'inimo. El uso de tasas de aprendizaje muy peque\~nas hace que el algoritmo tenga una convergencia estable hacia un m\'inimo, aunque el tiempo necesario para alcanzarlo puede llegar a ser muy alto. Como consecuencia de lo dicho anteriormente, y con el objetivo de disminuir el tiempo de convergencia del algoritmo, en la pr\'actica se suelen utilizar tasas de aprendizajes mayores a las te\'oricas. El aumento de la tasa de aprendizaje disminuye el tiempo de convergencia, pero tiene un efecto contraproducente: el algoritmo comienza a oscilar en torno a un m\'inimo, disminuyendo la probabilidad de alcanzarlo. El efecto de oscilaci\'on puede reducirse mediante la adici\'on de una tasa de momento, como se describi\'o en el cap\'itulo 3, pero no puede eliminarse.

 El algoritmo backpropagation es muy dependiente de los par\'ametros mencionados previamente. Dependiendo de la selecci\'on de par\'ametros realizadas el resultado de la aplicaci\'on del algoritmo ser\'a exitosa o no [Liu et alt, 2004]. Peque\~nas variaciones sobre los par\'ametros del algoritmo pueden conducir a resultados diferentes. El principal problema es que no existe un m\'etodo general que permita establecer el valor de estos par\'ametros [Branke, 1995]. Los par\'ametros que aseguran la convergencia para un determinado problema pueden no ser aplicables a otro problema. De esta manera, la selecci\'on de los par\'ametros del algoritmo se realiza en base a la experiencia del dise\~nador, y se realiza un refinamiento de los mismos mediante mecanismos de prueba y error. Esto produce un aumento en el tiempo total de dise\~no y entrenamiento de la red.

\item [M\'inimos locales] La superficie que define la funci\'on de error E (ecuaci\'on 8) en base a los par\'ametros de la red neuronal es compleja y esta llena de valles y colinas. Debido a la utilizaci\'on del gradiente para encontrar el m\'inimo de dicha funci\'on de error se corre el riesgo de que el proceso de entrenamiento quede atrapado en un m\'inimo local [Sutton, 1986]. Esta situaci\'on no es deseable, fundamentalmente si dicho m\'inimo esta localizado lejos del m\'inimo global.

 Existen algunos mecanismos para evitar que esto suceda. Una posible soluci\'on para evitar que el entrenamiento quede atrapado en un m\'inimo local es aumentar el n\'umero de neuronas ocultas de la red. Este mecanismo puede ayudar en aquellos casos en los que la red tiene escaso poder de representaci\'on interna, y no es capaz de distinguir entre dos patrones diferentes, proporcionando una misma salida para ambos patrones. Al aumentar el n\'umero de neuronas ocultas la red posee mayor cantidad de par\'ametros libres y puede conseguir una mejor representaci\'on interna.

 Otros mecanismos que ayudan a disminuir los efectos de este problema son la adici\'on de una tasa de momento al proceso de entrenamiento, utilizar una tasa de aprendizaje decreciente a lo largo del proceso, partir de otras configuraciones iniciales de la red, a\~nadir ruido al m\'etodo de gradiente, etc.

\item [Par\'alisis] El fen\'omeno de par\'alisis, tambi\'en conocido como saturaci\'on, se produce cuando la entrada total a una neurona de la red toma valores muy altos, ya sean positivos o negativos. Al utilizar funciones de activaci\'on sigmoidales, la funci\'on de activaci\'on posee dos as\'intotas horizontales. Si la entrada de la neurona alcanza un valor alto, la funci\'on de activaci\'on se satura y alcanza un valor de activaci\'on m\'aximo o m\'inimo.

 Cuando la funci\'on de activaci\'on se satura su derivada tiende a hacerse nula, haciendo que los par\'ametros de la red permanezcan invariables y, como consecuencia, la suma de los errores locales permanece constante por un largo periodo de tiempo [Kr\"ose y van der Smagt, 1993]. Aunque esta situaci\'on se suele confundir con un m\'inimo local, pues el error permanece invariable, en este caso es posible que despu\'es de un cierto tiempo el error comience nuevamente a decrecer.

 El fen\'omeno de par\'alisis del perceptr\'on multicapa ocurre fundamentalmente cuando los par\'ametros de la red toman valores muy altos. Un mecanismo para evitar esto consiste en partir de valores iniciales bajos.

\item [Condiciones iniciales] El conjunto de pesos iniciales de la red neuronal generalmente se selecciona de manera aleatoria. Sin embargo, el algoritmo backpropagation es muy dependiente de las condiciones iniciales seleccionadas [Kolen, 1991]. Peque\~nas variaciones realizadas sobre las condiciones iniciales pueden llevar a grandes diferencias en el tiempo de convergencia del algoritmo.
\end{listaDefiniciones}

 A esto hay que a\~nadir que los algoritmos de gradiente requieren entrenamiento supervisado (normalmente, no funcionan para el aprendizaje por refuerzo) y que las conexiones sean hacia delante (la retro-propagaci\'on del error no se puede aplicar en redes recurrentes). 

 Usando un algoritmo gen\'etico como m\'etodo de entrenamiento de la red, se solucionan algunos de estos problemas y otros se mitigan en cierto grado. Con el algoritmo gen\'etico, se puede usar el aprendizaje por refuerzo y se pueden entrenar redes recurrentes sin problema. No se tienen requerimientos para la funci\'on de activaci\'on, por lo que aumenta su adaptabilidad. Se cambia la dependencia de los par\'ametros de ese algoritmo y ahora depende de los par\'ametros del algoritmo gen\'etico, estos par\'ametros son m\'as flexibles y se pueden alterar en medio del entrenamiento. El algoritmo gen\'etico es mucho menos tendente a estancarse en m\'inimos locales porque no utiliza la informaci\'on del gradiente y porque explora varios puntos (tantos como individuos tenga la poblaci\'on) del espacio de b\'usqueda simult\'aneamente. El fen\'omeno de saturaci\'on se produce cuando una neurona alcanza un m\'aximo o un m\'inimo. En este caso, la derivada de la funci\'on de activaci\'on se hace nula, y los pesos de la red permanecen invariables. Como el m\'etodo propuesto no hace uso de la derivada de la funci\'on de activaci\'on, el efecto de este fen\'omeno es completamente eliminado. Los valores iniciales de los pesos tambi\'en pueden afectar al algoritmo gen\'etico, en especial si son muy altos (ya sean positivos o negativos), pero existen experimentos que permiten afirmar que el m\'etodo propuesto es menos dependiente de los valores iniciales que el algoritmo backpropagation \cite[Bertona2005]{Bertona2005}.

*** Algoritmos gen\'eticos
#+LaTeX: \label{anaFortYGene}

Un algoritmo gen\'etico es independiente del problema, lo cual lo hace un algoritmo robusto, por ser \'util para cualquier problema, pero a la vez d\'ebil, pues no est\'a especializado en ninguno. Hay que elegir la codificaci\'on de los cromosomas para cada caso concreto. Sin embargo, con nuestro m\'etodo siempre c\'odificaremos los cromosomas de manera similar (con una red neuronal) y s\'olo ser\'a necesario definir la funci\'on de fitness, elegir la topolog\'ia de la red, codificar las entradas y las salidas. Aunque la codificaci\'on de \'estas pueda admitir varias posibilidades (y algunas puedan ser m\'as ventajosas que otras) la red debe aprender a interpretar las correctas relaciones entre entradas y salidas por s\'i misma.

** TODO Objetivos
#+LaTeX: \label{anaObjetivos}

*** Implementación de la librería

En el presente proyecto se pretende construir una librer\'ia de programaci\'on en C++ para la utilizaci\'on de redes neuronales con entrenamiento mediante algoritmos gen\'eticos. Se quiere que sea lo m\'as flexible posible en cuanto a la estructura de la red, para poder, en un futuro, determinar la topolog\'ia tambi\'en de forma gen\'etica. Por tanto, con la librer\'ia implementada debe ser posible crear una cualquier red con una arquitectura arbitraria. Deben ser posibles conexiones recurrentes y conectar capas con tipos de datos diferentes (por ejemplo, que una capa cuya salida son n\'umeros en coma flotante debe poder usar como entrada una capa que tiene bits como salida).

 Como los entrenamientos pueden ser costosos en tiempo de ejecuci\'on, la librer\'ia debe estar paralelizada internamente al menos para la ejecuci\'on de redes neuronales. Esta paralelizaci\'on debe poder aprovecharse por los sistemas m\'as extendidos para que pueda ser utilizada en proyectos que aprovechen la computaci\'on voluntaria.

*** Investigación

 Se probar\'a la librer\'ia en casos concretos con el fin de contestar a las siguientes cuestiones:

1) ?`Qu\'e ventajas en el rendimiento se pueden obtener gracias a la paralelizaci\'on?

2) ?`Se puede simplificar la estructura de las redes neuronales para mejorar la paralelizaci\'on? ?`Qu\'e efecto tienen las funciones de tipo escal\'on (que permiten codificar la salida de cada neurona como un bit en vez de como un n\'umero real) tanto en el rendimiento como en el aprendizaje? ?`Qu\'e efecto tiene la codificaci\'on de los pesos en estructuras discretas (en lugar de n\'umeros reales) tanto en el rendimiento como en el aprendizaje?

3) ?`Qu\'e operadores gen\'eticos resultan m\'as adecuados para el entrenamiento en diferentes problemas? ?`Qu\'e valores de los par\'ametros del algoritmo gen\'etico resultan m\'as adecuados para el entrenamiento en diferentes problemas?

4) ?`Para qu\'e tipo de problemas resulta m\'as adecuado el m\'etodo propuesto? 

\newpage
** TODO Especificaciones de la librería a implementar
#+LaTeX: \label{anaEspec}
** TODO Consideraciones generales de diseño
#+LaTeX: \label{diseno}
* Dise\~no del algoritmo gen\'etico 
#+LaTeX: \label{disenoGene}
** Funcionamiento general
#+LaTeX: \label{disenoGeneFunc}

Como se vió en la sección \ref{basTeoGenetEstan} existen diferentes enfoques en cuanto a la gestión de la población de individuos. El algoritmo genético original adoptaba la política de reemplazo generacional [biblio], con el que la población completa es reemplazada en cada generación. En cambio, la política de estado estacionario [biblio], adoptada por varios algoritmos genéticos posteriores, reemplaza la población selectivamente. Es posible, por ejemplo, que mantener uno o varios miembros de la población por varias generaciones, siempre que estos mantengan su puntuación por encima de otros individuos de la población. Nuestra gestión de la población debe permitir ambas posibilidades de forma configurable.

Para ello, mantendremos a la población como una lista ordenada en la que se irán insertando (también ordenadamente) los nuevos individuos producidos. Si tras una inserción se tienen más individuos que el tamaño máximo, el peor individuo (sea el nuevo o no) será desechado. Si dos individuos comparten la misma puntuación al ser comparados durante una inserción, se le dará ventaja al nuevo individuo siguiendo el criterio de busqueda neutral [biblio]. Este comportamiento es el propio del estado estacionario. Para obtener el comportamiento generacional, así como diferentes híbridos entre las dos posibilidades, definiremos una variable configurable para la población. Tras generar a los individuos de la siguiente generación, el sistema mirará esta variable para saber cuantos de los antiguos individuos debe conservar para competir con los nuevos y simplemente elimina al resto. Si el numéro de individuos a preservar es 0, el comportamiento será el generacional puro. Si el número de individuos a preservar es igual al tamaño máximo de la población (o es un número negativo), no se eliminará a ningún individuo de la generación anterior y todos ellos tendrán la oportunidad de sobrevivir compitiendo con los de la nueva generación. Si el número es algo intermedio entre 0 y el tamaño máximo de la población, estaremos usando un híbrido entre las políticas de reemplazo generacional y la de estado estacionario.

En general, para cada nueva generación se realiza la siguiente secuencia de acciones:

1) Selección: se puede definir una cantidad independiente de individuos a seleccionar con cada operador de selección. De esta manera, se pueden utilizar varios operadores de selección simultaneamente y combinarlos de infinidad de formas. Se deben seleccionar un mínimo de dos progenitores en cada generación para que el siguiente fallo no resulte en error.

2) Cruza: una vez seleccionados los progenitores, se genera a partir de ellos la descendencia, los nuevos individuos. Los progenitores se van eligiendo aleatoriamente y si van marcando para no ser usados dos veces. Si se han seleccionado menos individuos de los que se quieren generar mediante cruza, cuando todos hayan sido usados una vez se desmarcarán para poder ser reutilizados y continuar con la generación de la descendencia mediante la cruza. Por tanto, el número de nuevos individuos por generación puede ser tanto mayor como menor al número de progenitores seleccionados. Además, como ocurría en la selección, varios operadores de cruza diferentes pueden combinarse también. En este caso, cada operador de cruza puede ser aplicado a un nivel de cruza diferente (ver sección \ref{disenoGeneNiv}) y cada una de estas combinaciones se le puede asignar un número independiente de individuos a generar por cruza. Por tanto, en este caso las posibilidades son aún más abundantes que para la selección.

3) Olvido: a cada uno de los individuos de la descendencia se le aplica el operador de olvido determinístico o probabilístico (o los dos, aunque no tenga mucho sentido) como se detalla en la sección \ref{disenoGeneMut}.

4) Mutación: de forma similar al paso anterior, sobre cada uno de los individuos de la descendencia se le aplica el operador de mutación determinístico o probabilístico (o los dos, aunque de nuevo no tenga mucho sentido) como se detalla en la sección \ref{disenoGeneMut}.

5) Preservación de individuos antiguos: como se ha comentado antes, se puede definir un número de individuos antiguos a conservar en cada generación. Se mirará la variable "individuos a preservar" para conservar a los mejores y se eliminarán los que sean peores. Si la variable contiene un cero, se estará aplicando la política de reemplazo generacional, pues en tal caso se eliminarían en este paso todos los individuos antiguos.

6) Se probarán e insertarán ordenadamente en la población los individuos de la descendencia. Puede que alguno no llegue a estar en la población como tal si no hay hueco para él. Nótese que se han podido generar más descendientes en el paso 2 de lo que se haya definido como el tamaño máximo de la población. Y, además, puede que estos individuos tengan que competir no sólo con los individuos de su generación, sino con los conservados en el paso 5.

Para generar la popblación inicial, se tomará un individuo de ejemplo del que se copiará la estructura de la red neuronal para generar individuos aleatorios (con pesos y umbrales aleatorios) que se irán insertando ordenadamente en la población (lo que implica evaluarlos) hasta completar el tamaño máximo de la población. El criterio que se ha elegido es el de maximizar el fitness. La tarea debe ser diseñada de tal forma que un individuo con un fitness mayor sea mejor que uno con fitness menor.

** Operadores de selección
#+LaTeX: \label{disenoGeneSel}
Los operadores de selección que se han implementado son los siguientes: ruleta, ranking, torneo y truncado.

*** Ruleta
#+LaTeX: \label{disenoGeneSelRule}

Este tipo de selección sólo admite individuos con fitness mayor que cero, si el peor individuo no cumple esta condición se lanczará un error.
Para la selección por ruleta lo primero que hay que hacer es sumar el fitness de todos los individuos (S).
Luego, por cada individuo a seleccionar por este método:

1) Se elige un número aleatorio del intevalo (0, S), que llamaremos E (de elegido).

2) Se recorre la población desde el mejor individuo. Si el fitness del individuo (más el fitness de los individuos anteriores) es mayor que E, se selecciona ese individuo. Si no, se pasa al siguiente, acumulando el fitness de este individuo para la siguiente comparación.

*** Ranking
#+LaTeX: \label{disenoGeneSelRank}

Para la selección por ranking se puntuan los individuos dependiendo de su posición en la población.
Tradicionalmente se asigna N (el máximo de la población) al mejor, N-1 al segundo mejor, y así sucesivamente hasta llegar al peor individuo al que se asigna un fitness de 1. En nuestro caso hemos querido que sea más configurable y hemos añadido dos variables configurables: el "salto para el ranking" y la "base para el ranking". El salto para el ranking es la diferencia de fitness entre un individuo y el siguiente, en el ejemplo anterior era 1, pero podemos aumentar la presión selectiva incrementando este número. La "base para el ranking" se suma al fitness de toda la población. Por ello, para utilizar el ranking tradicional, los valores por defecto son "salto para el ranking" = 1 y "base para el ranking" = 0.

Una vez tenemos estos fitness auxiliares, se realiza la selección siguiendo un método similar al de la ruleta, pero con estas puntuaciones en lugar de los fitness originales.

*** Por torneo
#+LaTeX: \label{disenoGeneSelTorn}

Para la selección por torneo se cuenta con una variable configurable "tamaño del torneo" que no puede ser menor que el tamaño máximo de la población. En caso contrario se generará un error. Para cada individuo a seleccionar por este método:

1) Se preseleccionan "tamaño del torneo" individuos de la población de forma totalmente aleatoria pero evitando que se repitan.

2) Se selecciona el individuo más apto de todos los que están en el torneo.

El tamaño típico y, por ello, el valor por defecto que hemos seleccionado para el tamaño del torneo es 2.

*** Elitísta o por truncado
#+LaTeX: \label{disenoGeneSelTrunc}

La selección elitista es la más sencilla de todas. Simplemente se cogen los N (donde N es el número de individuos a seleccionar por este método) más aptos desde el principio de la lista ordenada de la población.

** Operadores de cruza
#+LaTeX: \label{disenoGeneCruz}

Aunque aceptamos varias definiciones de gen, como se explica en la sección \ref{disenoGeneNiv}, en esta sección trataremos las formas en que se pueden cruzar dos individuos, produciendo dos descencientes con los genes de los progenitores combinados de forma complementaria (todos los genes de los progenitores irán a un descendiente o a otro, aunque puede que uno de los descendientes se deseche si sobra). 

Todos los esquemas de cruce se aplican primero sobre un vetor de bits (cada bit representa un gen) y luego se aplica el crossover usando ese vector. Esto permite compartir una sóla interfaz para la cruza a bajo nivel. Dada la diversidad de implementaciones de las redes neuronales, la cantidad de código se multiplicaría con los distintos esquemas de cruza de forma que el código sería mucho más complicado de desarrollar y mantener. Esto, además, permite extender nuestro algoritmo genético con nuevos esquemas de cruza sin necesidad de modificar las distintas implementaciones (C, SEE2, CUDA). También es posible crear una nueva implementación (por ejemplo, usando openCL) sin necesidad de implementar por separado cada uno de los esquemas de cruza.

*** Uniforme
#+LaTeX: \label{disenoGeneCruzUni}

Para la cruza uniforme, se debe indicar un parámetro "probabilidad", que puede ser configurado independientemente para cada nivel de cruza.
Para generar el hijo A, por cada gen de los progenitores, se elige un número aleatorio en el intervalo (0, 1). Si el número es menor que la probabilidad, se cogerá el gen del progenitor B, en caso contrario, el del progenitor A. Para generar el hijo B, se utilizan los genes que no se hayan utilizado para el descendiente A.

La probabilidad por defecto para todos los niveles es 0.7.

*** Proporcional
#+LaTeX: \label{disenoGeneCruzProp}

Este modo de cruza funciona de forma similar al anterior, con la diferencia de que la probabilidad no es especificada por el usuario, sino que se calcula a partir de los fitness de los progenitores. Tradicionalmente, se usa la siguiente fórmula:

\begin{equation}\label{eqCruzProp}
  probabilidad = finessA / (fitnessA + fitnessB)
\end{equation}

Esta fórmula sólo admite finess positivos, pero en nuestro caso hemos admitido más casos.

1) Si ambos son positivos, se aplica la fórmula \ref{eqCruzProp}.

2) Si ambos fitness son iguales a cero, la probabilidad es 0.5.

3) Si fitnessA es positivo y fitnessB es menor o igual que cero, la probabilidad es 1.

4) Si fitnessA es menor o igual que cero y fitnessB es positivo, la probabilidad es 0.

5) Por último, si ambos son negativos, se aplica otra fórmula parecida a la primera (pero en este caso, cuanto menos negativo mejor):

\begin{equation}\label{eqCruzPropNeg}
  probabilidad = -finessB / -(fitnessA + fitnessB)
\end{equation}

Aunque contemplar estos casos especiales puede parecer una complicación innecesaria, nos permite que este tipo de cruza sea compatible con tareas que admiten fitness negativos en lugar de tener que lanzar un error.

*** Multi-punto
#+LaTeX: \label{disenoGeneCruzMulti}

En la literatura convencional, frecuentemente se mencionan la "cruza de un punto" o la "cruza de dos puntos", pero en realidad son casos concretos de la más general "cruza multipunto". Por ello, se ha decido implementar sólo esta última, creando un parámetro "número de puntos" que puede ser configurado independientemente para cada nivel de cruza. El número de puntos por defecto para todos los niveles es 1.

El funcionamiento general es el siguiente:

1) Se marcan aleatoriamente "número de puntos" genes, que serán como puntos de corte.

2) Desde el inicio, hasta el primer punto, se cogen los genes del progenitor A. A partir desde este punto de corte hasta el siguiente, se gogen los genes del progenitor B, luego de nuevo los del A y así sucesivamente hasta el final.

De esta manera, se va alternando el progenitor en cada punto. Como siempre, el decendiente B usará los genes que no haya usado el descendiente A.

** Niveles de cruza
#+LaTeX: \label{disenoGeneNiv}

*** Pesos y umbrales
#+LaTeX: \label{disenoGeneNivPes}

Este es el nivel de cruza más pesado y sensible de todos. Todas las capas se colocan una detrás de otra con sus pesos seguidos de sus umbrales. Cada peso o umbral es un gen.

*** Neurona
#+LaTeX: \label{disenoGeneNivNeu}

En este caso cada gen es una neurona, con todos sus pesos y con su umbral. Los pesos son los que se multiplican por las entradas a esta neurona.
Se colocan en orden todas las capas y todas las neuronas de cada capa.

*** Neurona invertida
#+LaTeX: \label{disenoGeneNivNeuInv}

Este caso es muy similar al anterior, pero se cambia la definición de lo que se considera una neurona. En este caso, junto con el umbral, forman parte del mismo gen los pesos que se multiplican por la salida de esta neurona, en lugar de los que utiliza esta neurona para calcular su estado. Esta representación ha sido también denominada "neurona en fregona" [biblio].

*** Capa
#+LaTeX: \label{disenoGeneNivCap}

Para el nivel de capa, cada capa, valga la redundancia, es considerada un gen. Una capa incluye todas sus neuronas con sus pesos y umbrales, entendiendo una neurona como se hace en el apartado \ref{disenoGeneNivNeu} y no como la neurona invertida.

Aunque intuitivamente se puede pensar que este tipo de cruza no será muy útil si las capas son muy pocas o muy grandes, se ha decido implementar también este nivel de cruza para comparar el aprendizaje.

** Mutación y olvido
#+LaTeX: \label{disenoGeneMut}

La forma en que se implementan el operador de mutación y el de olvido son muy similares. La principal diferencia es que mientras el operador de olvido o reset simplemente pone a cero el peso o umbral que toque, el de mutación le suma un número aleatorio del intervalo (-X, X), donde X es un parámetro configurable que llamaremos "rango de mutación", que por defecto toma el valor 1. En cierto sentido, se podría considerar al operador de olvido como un tipo especial demutación.

Por lo demás, los dos operadores tienen dos formas de ser empleados: probabilística y determinista.

*** Probabilística

Esta forma de mutación es la más habitual en los algoritmos genéticos. Se usa una probabilidad parámetro ("probabilidad de mutación" o "probabilidad de olvido", ambas 0 por defecto) para calcular con cada peso y umbral si será mutado o no. Se elige un número aleatorio entre 0 y 1 y si el número es menor que la probabilidad, se realiza la acción correspondiente. Si es mutación sumar al peso la mutación que se obtiene a partir del rango como se ha comentado anteriormente y si es olvido el peso se iguala directamente a cero.

*** Determinista

Para evitar repetir el calculo de la probabilidad tantas veces y mejorar el rendimiento, se ofrece esta otra modalidad de mutación, con la esperanza de que el aprendizaje no se vea afectado negativamente.

En este caso en lugar de determinar probabilisticamente y peso por peso si un peso debe mutar o no, se configura un número determinado de mutaciones (u olvidos) que se aplicarán a cada individuo. Las variables "número de mutaciones" y "número de olvidos" tienen ambas por defecto el valor 0. Sabiendo el número de mutaciones que se van a realizar, sólo queda determinar aleatoriamente qué pesos y/o umbrales concretos serán mutados (u olvidados).

Para activar cualquiera de las dos modalidades en cualquiera de los dos operadores, basta con dar un valor positivo a las variables "probabilidad de mutación", "probabilidad de olvido", "número de mutaciones" y "número de olvidos". Como es habitual, se pueden emplear simultaneamente las varias opciones. En este caso también puede no activarse ningún tipo de mutación ni de olvido.
* TODO [2/3] Paralelizaciones en las redes neuronales
#+LaTeX: \label{disenoParal}
** DONE Introducción

Tanto los algoritmos genéticos como las redes neuronales requieren cálculos que presentan paralelismos inherentes. Para este proyecto se ha escogido explotar exclusivamente los de las redes neuronales. Por ejemplo, con múltiples CPUs y GPUs. pero la implementación se podría extender para aprovechar también los de los algoritmos genéticos, aunque esto requeriría cambios no triviales en el modo en que las poblaciones son procesadas cada generación si se quiere extender la librería en ese sentido. Nuestras paralelizaciones solamente usan una CPU simultáneamente. Se han optado por dos alternativas que se comparan.

Gracias al diseño modular por el que se ha optado, es posible añadir otras implementaciones paralelas de las redes neuronales (por ejemplo, usando el lenguaje OpenCL) tan sólo implementando unos pocos métodos en un par de clases que extiendan las clases Fachada (TODO nota al pie sobre el patrón de diseño) que contienen toda la parte susceptible de ser cambiada para obtener mejor rendimiento.

La primera alternativa implementada es la utilización del conjunto ampliado de instrucciones SSE2 para acceder al co-procesador XMM. Este co-procesador está presente en todos los computadores recientes de la familia x86 liderada por Intel, que es probablemente la arquitectura más extendida en el mundo. La arquitectura vectorial del co-procesador multimedia permite operar sobre varios datos similares al mismo tiempo. En la sección \ref{disenoParalXMM} se explica con más detalle la arquitectura del mismo y como se ha utilizado para paralelizar nuestro algoritmo.

La segunda paralelización obedece a una tendencia bastante más reciente y en alza conocida como GPGPU (General Purpose Graphic Processor Units), que consiste en utilizar las terjetas especializadas en procesar gráficos para procesar otros cálculos que posiblemente nada tengan que ver con los gráficos. Debido a la gran demanda proveniente de diseñadores gráficos y, sobre todo, aficionados a los videojuegos, estos dispositivos comenzaron a tener unas especificaciones que resultaban muy atractivas a gran variedad de investigadores como físicos o bioquímicos. Al principio los investigadores dependian de su ingenio para mapear sus problemas específicos a un algoritmo que usase primitivas gráficas, pero con el creciente interés de esta técnica, los fabricantes decidieron ampliar su mercado de consumidores creando lenguajes específicos para este fin mucho más amigables y con facilidades para la optimización. El lenguaje C CUDA de NVIDIA, con el que desarrollamos la paralelización descrita en la sección \ref{disenoParalCUDA} es un ejemplo de estos lenguajes. Más tarde las compañías decidieron crear un lenguaje común que sirviese para todas las GPUs sin importar la marca llamado OpenCL. Hoy en día muchas de los supercomputadores más potentes del mundo utilizan múltiples GPUs para obtener los altos rendimientos que requieren[fn:cudaSuperComp].

** DONE Ensamblador con SSE2
#+LaTeX: \label{disenoParalXMM}
*** Introducción al coprocesador XMM
#+LaTeX: \label{disenoParalXMMintro}

Como ya se ha mencionado, el coprocesador XMM utiliza una arquitectura vectorial (SIMD, Single Instruction Multiple Data, figura \ref{SIMDexecutionModel}). Esto significa que tiene varias ALUs que pueden realizar la misma operación sobre múltiples datos en paralelo. Como veremos, la tecnología XMM parmite algunas cosas más como operaciones de reducción sobre el vector de datos. XMM es una extensión de MMX (que introducía el célebre procesador Pentium XMM) en la que se dobla el tamaño máximo de los vectores (de 64 a 128 bits) y se añaden algunas instrucciones. Este coprocesador es utilizado también para las operaciones habituales con números de doble precisión, por lo que alternar frecuentemente entre los dos usos puede resultar en serias penalizaciones al rendimiento.

#+CAPTION:    Modelo de ejecución SIMD. En nuestro caso el destino se almacena en el mismo registro de origen 1.
#+LABEL:      SIMDexecutionModel
#+ATTR_LaTeX: scale=0.4
[[./img/SIMD_Execution_Model.jpg]]

El tamaño de los registros-vectores depende del tipo de datos a procesar: se pueden tener 2 números en doble precisión, 4 números en coma flotante, 4 enteros (con o sin signo), 8 enteros cortos (short), 16 bytes, 128 bits para operaciones lógicas, etc. La figura \ref{XMMregister} lo ilustra con más detalle. 

#+CAPTION:    Posibles usos vectoriales de los 128 bits de un registro XMM.
#+LABEL:      XMMregister
#+ATTR_LaTeX: width=\textwidth
[[./img/XMMregisters.jpg]]

No es preciso indicar qué tipo de datos contiene cada registro vector, los datos de cada registro XMM serán interpretados de una manera u otra dependiendo de la operación que se aplique sobre ellos. El compilador o en este caso el programador es responsable de mantener la integridad de los mismos. Por ejemplo, la instrucción PADDB, sumará dos registros interpretándolos como Bytes idependientes, PADDW sumará palabras (2 Bytes) y PADDD los tomará como palabras dobles (4 Bytes, el tamaño del típico int de C). Si queremos saturación con o sin signo debemos utilizar instrucciones que lo indiquen como PADDSB (saturación con signo) o PADDUSB
 (saturación sin signo). ADDPS para números en coma flotante con precisión simple (4 bytes), etc. Las instrucciones para usar registros MMX pertenecen al conjunto extendido SSE y las que operan sobre registros XMM pertenecen a SSE2.

*** Operaciones vectoriales con números en coma flotante
#+LaTeX: \label{disenoParalXMMfloat}

La función desarrollada para XMM para optimizar los cálculos de una red neuronal o capa de tipo float (sin optimizar la activación) puede ser llamado desde C/C++ usando el siguiente prototipo:

#+begin_src c
    void XMMreal(float* bufferEntrada, unsigned numeroBloques,
                 float* pesos, float &resultado);
#+end_src

Para calcular el estado de una neurona de tipo float se escribirá en la variable de salida resultado (sobre la que se tendrá que aplicar posteriormente la activación), tomamos como entrada dos vectores y un entero. Los arrays son el buffer de entrada (la salida de una capa de tipo float) y otro con los pesos asociados a esa entrada para esta neurona de salida concreta. El entero nos indica el número de bloques de entrada que han de ser procesados. Como se trada de números flotantes en precisión simple, podemos operar con cuatro de ellos simultáneamente en el coprocesador XMM. Por tanto los bloques son de tamaño 4 y los ambos arrays deben reservar un tamaño en memoria que sea múltiplo de cuatro floats. Los números sobrantes también serán procesados, por lo que es preciso anular las entradas y/o los pesos para evitar que estos valores sobrantes no afecten al resultado final.

Internamente, se van recorriendo ambos vectores, multiplicándo los elementos y acumulando los resultados. El núcleo del bucle contiene estas dos instrucciones:

#+begin_src asm
 	MULPS XMM0, XMM1
	ADDPS XMM3, XMM0
#+end_src

La primera multiplica 4 entradas contenidas en XMM0 por sus pesos correspondientes contenidos en XMM1. La segunda instrucción va acumulando los resultados en XXM3. Al final sólo hay que sumar los 4 subtotales que hay en cada uno de los elementos de XMM3 y devolver el resultado en la variable resultado.

*** Operaciones vectoriales con Bytes
#+LaTeX: \label{disenoParalXMMbyte}

Para poder aprovechar al máximo las capacidades del coprocesador XMM, se decide implementar un tipo de capa con unas características concretas.
La primera es que el estado de las neuronas será almacenado en bits, ya se trate de neuronas binarias cuyos estados pertenecen al conjunto {0, 1} o de neuronas de tipo bipolar cuyos estados pueden ser {-1, 1}. Esto nos ahorrará mucho espacio en memoria y, sobre todo, muchas lecturas de memoria para procesar el mismo número de neuronas de entrada.

La segunda característica es que los pesos tendrán valores pertenecientes al conjunto de enteros [-128, 127] y, por tanto, cada peso ocupará un byte en memoria. Esto significa que, además de leer menos datos de memoria como ocurre con las entradas, podremos procesar los pesos de 16 en 16 (los bytes que caben en un registro XMM de 128 bits) en lugar de hacerlo de 4 en 4 como en la función anterior que operaba con números en copa flotante con precisión simple. El hecho de que los pesos puedan tomar menos valores nos permitirá además reducir el espacio de búsqueda en el algoritmo genético, pero a la vez impone mutaciones enteras y, por tanto, cambios más bruscos. Los resultados en términos de aprendizaje al comparar los dos tipos de pesos se encuentran en el apartado \ref{aprendDiscretLineales}.

Las funciones para las capas de tipo binario y las de tipo bipolar son muy similares, sus prototipos son:

#+begin_src c
    int XMMbinario(void* bufferEntrada, unsigned numeroBloques, unsigned char* pesos);
    int XMMbipolar(void* bufferEntrada, unsigned numeroBloques, unsigned char* pesos);
#+end_src

Se ha escogido en este caso devolver el resultado directamente en lugar de usar un parámetro de salida, pero la decisión no tiene consecuencias trascendentes. Se explicará primero como funciona internamente la primera de las funciones y luego, para la segunda, sólo se explicarán las partes que la hacen diferente. Para una mayor claridad a la hora de presentar porciones de código, usaremos nombres descriptivos (similares a nombres de variables en lenguajes de más alto nivel) en lugar de los nombres de los registros XMM que se han utilizado en el código real: XMM0, XMM1...XM7.

Como en el caso en coma flotante, las entradas y los pesos se procesarán por bloques y se deberán rellenar adecuadamente los pesos y entradas para evitar que se sumen cálculos no desados. Para el caso bipolar es imprescindible anular los pesos, no basta con anular las entradas pues los bits nulos serán interpretados por el algortimo como -1 en vez de como 0. Para las entradas, los bloques contendran 128 bits, cada uno representando a una neurona de entrada. 

Para los pesos, los bloques serán de 16 bytes, uno para cada peso. De este modo, por cada bloque de entrada completo se requerirán 8 bloques de pesos (8 * 16 = 128). El número de bloques que se recibe por parámetro se refiere al número de bloques de pesos. Así, si no se van a usar todas las neuronas de entrada en el último bloque, no hay que seguir leyendo pesos que se sabe que deben ser nulos para el funcionamiento correcto. Esos bloques sobrantes no han de procesarse, ni siquiera almacenarse en memoria. Lo importante es que dentro del bucle principal que recorre las entradas (que se irán almacenando en el registro XMMentrada), hay un sub-bucle que se ejecuta hasta ocho veces, una vez por cada 16 pesos que se requieran, que se irán almacenando en el registro XMMpesos.

Para acceder a los bits de un bloque de entrada de 16 en 16 (el número de pesos que se van a procesar en cada vuelta del bucle de pesos), usaremos el registro XMMmascara que tendrá un bit activo por cada uno de los 16 bytes del bloque. La máscará se inicializará por cada bloque de entrada con 16 bytes iguales a 128 (el primer bit activo y todos los demás nulos en binario) y luego se irá deplazando todo el registro una posición a la derecha por cada nueva lectura hacia XMMpesos que no suponga también una lectura en XMMentradas y, por tanto la inicialización de la máscara. Los 16 byes con un 128 vienen de una constante en memoria. Para evitar la penalización que supondría leer esta constante por cada 8 bloques de pesos leídos, se reservará el registro XMM128 de los 8 disponibles (con arquitecturas de 64 bits, el coprocesador XMM dispone de 16 registros en vez de 8) y que en todo momento contendrá dicha constante leída de memoria una sola vez al principio de la función. Para ello se usará la siguiente instrucción (la misma que se usa para leer entradas y pesos):

#+begin_src asm
	MOVDQU XMM128, [cte_mascara_en_mem];
#+end_src

Cuando se quiera inicializar la máscara simplemente se utilizará la siguiente instrucción, que copia el contenido de un registro a otro y es mucho menos costosa que la anterior:

#+begin_src asm
	MOVDQA XMMmascara, XMM128
#+end_src

Para no estropear la mascará, previamente se ha copiado su contenido a XMMaux, sobre el que se harán varias operaciones. Ahora para acceder a cada uno de los bits en la posición que toque de las ocho, bastará con hacer un AND lógico con el registro de entradas. 

#+begin_src asm
	PAND XMMaux, XMMentradas
#+end_src

Ahora dependiendo de si el byte tiene algún bit activo o no, se sumará o no el peso correspondiente. Esta colocación de los bits con respecto al orden en que se cogen los pesos no es igual a la del algoritmo equivalente implementado en C, por tanto la función de activación de los tipos binario y bipolar para la implementación SSE2 (aunque esté escrita en C), debe tener en cuenta la disposición especial de los bits de entrada que espera esta función. Lo mismo sucede para los métodos que copian vectores de bits desde los Buffer dependientes de la implementación a los vectores más generales de la clase Interface que usamos para acceder a las entradas y salidas de la red neuronal desde el exterior, independizando así el manejo de estos datos de la representación interna que pueda tener cada implementación, como ya se ha descrito en la sección \ref{anaEspec}.

¿Cómo llegamos a partir de lo que tenemos en XMMaux (cada byte tiene en bit activo o no, dependiendo del estado de la neurona de entrada procesada) y en XMMpesos a un registro en el que sólo se tengan los pesos que correspondan a neuronas activas y que tenga anulados los pesos que corresponden a neuronas inactivas? Son necesarios algunos trucos de bastante bajo nivel que son realmente la parte más interesante de las funciones. Primero ejecutaremos la siguiente instrucción:

#+begin_src asm
    PCMPEQB XMMaux, XMMnulo
#+end_src

PCMPEQB compara cada byte de ambos registros y, si son iguales, pone a 255 (todos los bits activos) del byte en el primer registro (XMMaux). Si son distintos, pone cero (todos los bits inactivos) en ese mismo byte. En nuestro caso lo estamos comparando con un registro en el que todos los bits son nulos. Por ello, los bytes de XMMaux que tuviesen un bit activo se anularán enteros (por ser distintos a cero) y los que no tuviesen ninguno activo tomarán el valor 255 (por haber sido iguales a cero). Pero nosotros queríamos justamente lo contrario, por lo que invertimos completamente XMMaux para obtener el resultado deseado.Para invertir un registro, ejecutamos XOR contra un registro que tenga todos los bits activos (XMM255):

#+begin_src asm
    PXOR XMMaux, XMM255
#+end_src

Para iniciar los registros XMMnulo y XMM255 no se requieren constantes en memoria. Basta con usar de nuevo instrucciones lógicas:

#+begin_src asm
    PXOR XMM255, XMM255
#+end_src

Como cualquier registro independientemente de su contenido inicial es "igual a sí mismo", la comparación activará el registro por completo.

#+begin_src asm
    PXOR XMMnulo, XMMnulo
#+end_src

Como XOR requiere uno y sólo uno de los bits de entrada activos para activar la salida y como de nuevo el registro es "igual a sí mismo", el registro se anulará todos sus bits.

Una vez que tenemos en XMMaux cada byte a 255 ó 0 dependiendo del estado del bit correspondiente a cada una de las 16 neuronas de entrada procesadas, podemos desechar los pesos que no deban sumarse con un simple AND:

#+begin_src asm
    PAND XMMaux, XMMpesos
#+end_src

En la figura \ref{mascaraBinariaXMM} se trata de ilustrar la forma de acceso a los bits individuales. 

#+CAPTION:    Ejemplo ilustrativo del acceso paralelo a los bits individuales.
#+LABEL:      mascaraBinariaXMM
#+ATTR_LaTeX: width=\textwidth
[[./img/ejemploXMM.jpg]]

Todavía tenemos que sumar los pesos entre sí y acumularlos. Este es el paso que consigue una mayor mejora en las optimizaciones binaria y bipolar con respecto a la flotante. Aunque no hay ninguna instrucción que nos permita sumar todos los bytes de un registro XMM directamente, existe otra que nos es muy útil porque hace una reducción similar. Se trata de PSADBW. Con registros MMX (de 64 bits en vez de 128), calcula la diferencia absoluta entre los bytes de cada registro operando y suma todas esas diferencias, dejando el resultado en los 4 bytes bajos del registro MMX. Con registros XMM, opera de forma similar pero dejando dos resultados: uno en la los 4 bytes bajos de los 8 bajos y otro en los 4 bajos  de los  8 altos. Es decir, duplica la operación. 

#+begin_src asm
    PSADBW XMMaux, XMMnulo
#+end_src

Si uno de los operandos es un registro nulo, la diferencia absoluta entre 0 y un número siempre es ese mismo número, por lo que simplemente sumara los bytes. Surge aquí un pequeño problema dado que suma los bytes sin tener en cuenta su signo, como si todos fueran positivos. Cómo queriamos los pesos pertenecientes a [­128, 127], debemos hacer algo al respecto.

Antes de ejecutar la instrucción anterior, ejecutaremos: 

#+begin_src asm
    PAND XMMaux128, XMMaux
#+end_src

Y así tendremos 128 en los bytes cuyos bits estaban activos. Después, en lugar de sólo una instrucción de reducción, ejecutamos:

#+begin_src asm
    PSADBW XMMaux, XMMnulo
    PSADBW XMMaux128, XMMnulo
    PSUBD XMMaux, XMM128
#+end_src

Esto equivale a restarle 128 a cada byte que fuesemos a sumar, porque se suman con PSADBW tantos 128 como pesos haya. Hay que tener en cuenta que los pesos pueden ser [­128, 127] pero no equivalen, por ejemplo, a los char de C++. En C++, los números se representan en complemento a dos mientras que en nuestra representación alternativa el 0 es el ­128, el 128 es el 0, el 129 el 1, etc. Realmente no es importante, siempre y cuando lo tengamos presente. Ya sólo queda sumar las dos partes. Después, se repite el proceso hasta completar los 8 bits por bytes, cargando cada vez 16 pesos nuevos. Luego se reinicia la máscara, se lee el siguiente bloquede entrada y se repite todo hasta que hayamos completado en número de bloques.

Al final, hay que sumar las dos partes (alta y baja) que se están acumulando en un registro XMM. Esto se omite, como la gestión del bucle, porque no tiene demasiado interés en lo que a nuestros esfuerzos de optimización se refiere.

La explicación que se ha dado se refería al algoritmo para neuronas binarias, que pueden tomar los valores {0, 1}. Para las neuronas bipolares que pueden tomar los valores {-1, 1}, el código es bastante similar, aunque ligeramnte más complicado. En este caso, todos los pesos se utilizan, simplemente unos cambian su signo y otros no. Ahora, cuando invertimos XMMaux, también conservamos el original y también lo operamos con AND con los pesos. El resultado son los pesos que tendrán que ser restados en vez de sumados. También lo operamos el registro auxiliar invertido con el XMM128, pues por cada peso restado se tendrá que sumar 128 (en vez de restarlo). Por ejemplo, 129 es sólo 1 en nuestra representación, por tanto, para restar 1 (restar un peso igual a uno), restamos 129 y sumamos 128.

Recordamos resumadiamente lo que hacíamos en el núecleo de la versión binaria para luego señalar las diferencias.

#+begin_src asm
	MOVDQA XMMaux, XMMmascara      ;copiamos la máscara en una mascara auxiliar

	PAND XMMaux, XMMentradas       ;obtenemos el valor del bit a procesar en cada byte
    PCMPEQB XMMaux, XMMnulo        ;si el bit estaba activo->se pone a 0 todo el byte, 
                                   ;si no-> se pone a 1 todo el byte (255)
	PCMPEQB XMM255, XMM255         ;ponemos 255 en todos los byes del registro XMM255
    PXOR XMMaux, XMM255            ;invertimos XMMaux 
                                   ;(ahora hay 255 en los bytes que tenian el bit que tocaba activo)

	MOVDQU XMMaux128, XMM128       ;128 en todos los bytes de XMMaux128
	PAND XMMaux128, XMMaux         ;128 sólo en los bytes que estaban activos

	MOVDQU XMMpesos, [ptrPesos]    ;leemos el bloque actual de pesos
	PAND XMMaux, XMMpesos          ;asi tenemos el peso de cada conexión 
                                   ;solamente en los bytes con el bit activo

	PSADBW XMMaux, XMMnulo         ;sumamos todos los bytes (los que estaban activos)
	PSADBW XMMaux128, XMMnulo      ;sumamos 128 por cada byte que estaba activo

	PADDD XMMacumulador, XMMaux    ;sumamos estos pesos a los ya sumados previamente
	PSUBD XMMacumulador, XMMaux128 ;sustraemos 128 por cada bit que estaba activo
#+end_src

En el caso bipolar se hacen más cálculos. Además de los dos primeros, como en el caso binario, para el caso bipolar se hacen los dos últimos cálculos descritos en esta lista:

1) Se suman todos los pesos de las neuronas activas
2) Se resta 128 por cada neurona activa
3) Se restan todos los pesos de las neuronas inactivas
4) Se suma 128 por cada neurona inactiva

Como ahora no tenemos que desechar ningún peso, sino sumar unos y restar otros, el código quedaría así:

#+begin_src asm
	MOVDQA XMMaux, XMMmascara      ;copiamos la máscara en una mascara auxiliar

	PAND XMMaux, XMMentradas       ;obtenemos el valor del bit a procesar en cada byte
    PCMPEQB XMMaux, XMMnulo        ;si el bit estaba activo->se pone a 0 todo el byte,
                                   ;si no-> se pone a 1 todo el byte (255)
	PCMPEQB XMMauxInv, XMMauxInv   ;ponemos 255 en todos los byes del registro XMMauxInv
    PXOR XMMauxInv, XMMaux         ;ponemos el inverso de XMMaux en XMMauxInv

	MOVDQU XMMaux128, XMM128       ;128 en todos los bytes de XMMaux128
	PAND XMMaux128, XMMauxInv      ;128 sólo en los bytes que estaban activos
	PSADBW XMMaux128, XMMnulo      ;sumamos 128 por cada byte que estaba activo
	PSUBD XMMacumulador, XMMaux128 ;sustraemos 128 por cada bit que estaba activo

	MOVDQU XMMaux128, XMM128       ;128 en todos los bytes de XMMaux128
	PAND XMMaux128, XMMaux         ;128 sólo en los bytes que estaban inactivos
	PSADBW XMMaux128, XMMnulo      ;sumamos 128 por cada byte que estaba activo
	PADDD XMMacumulador, XMMaux128 ;sumamos 128 por cada bit que estaba inactivo

	MOVDQU XMMpesos, [ptrPesos]    ;leemos el bloque actual de pesos
	PAND XMMauxInv, XMMpesos       ;asi tenemos el peso de cada conexión 
                                   ;solamente en los bytes con el bit activo
	PAND XMMaux, XMMpesos          ;asi tenemos el peso de cada conexión 
                                   ;solamente en los bytes con el bit inactivo

	PSADBW XMMauxInv, XMMnulo      ;sumamos todos los bytes (los que estaban activos)
	PSADBW XMMaux, XMMnulo         ;sumamos todos los bytes (los que estaban inactivos)

	PADDD XMMacumulador, XMMauxInv ;sumamos los pesos "positivos" al acumulador
	PSUBD XMMacumulador, XMMaux    ;sustraemos los pesos "negativos" al acumulador
#+end_src

Todavía se podrían mejorar las soluciones si contásemos con la arquitectura de 64 bits. En tal caso tendríamos 16 registros XMM en lugar de sólo 8, no habría que reusar tanto los registros y algunos trucos (como los de poner a 255 ó a 0 todo un registro) podrían realizarse solamente una vez al principio en vez de cada vez que necesitamos alguno de estos valores en un registro que usamos para multiples cosas. Hemos optado por la compilación para 32 bits por su mayor portabilidad. En los sistemas operativos de 64 bits se puede simular la arquitectura de 32 bits y ejecutar nuestra optimización. No sucede lo mismo al contrario: si hubiesemos optado por la implementación de 64 bits no podríamos ejecutar la optimización sobre un sistema operativo de 32 bits.

Como hemos dicho, la colocación de los bits para la implementación XMM debe adaptarse para que se puedan obtener los mismos resultados que con el algoritmo implementado en C. Pero además en el algoritmo C no se puede usar el tipo char para los pesos (hay que usar unsigned char) y hay que restarles 128 antes de operar con ellos. Esto podría ralentizar "injustamente" al algoritmo C, por lo que también se hicieron pruebas de rendimiento sin restar 128 y usando el tipo char para comparar los tiempos. Logicamente, esa implementación C no obtiene resultados equivalentes a los de la SSE2, pero tan sólo se pretendía comparar el rendimiento. Sorprendentemente, con esta implementación C se obtenían resultados aún peores. También se probó usadno el tipo unsigned char pero sin restar 128 y el rendimiento era de nuevo ligeramente peor. Por alguna razón que no alcanzamos a explicar, el algoritmo en C funciona más rápido si ha de restar 128 a cada peso. Por ello, dejamos de lado nuestra preocupación sobre la posible penalización causada por nuestra representación de pesos en bytes.

** TODO [2/5] GPGPU con CUDA
#+LaTeX: \label{disenoParalCUDA}

Debido a la insaciable demanda de mercado de gráficos 3D de alta definición y en tiempo real, las unidades de procesamiento gráfico (Graphic Processor Unit, GPU) han evolucionado en procesadores altamente paralelos y multihilo, con muchos núcleos, tremenda capacidad de computación y con gran ancho de banda de memoria. La técnica consistente en utilizar el este poder computacional para realizar trabajos de proposito general, que pueden no tener nada que ver con los gráficos se denomina GPGPU (General Purpose Graphic Processor Unit). Los pioneros de la técnica buscaban homorfismos entre los algoritmos que pretendían ejecutar y cálculos que las librerías gráficas realizan internamente. 

Gracias a los lenguajes de alto nivel especializados para GPGPU como C CUDA u OpenCL, ya no es necesario modelar tu problema utilizando conceptos puramente gráficos como superficies y texturas. Sin embargo, para poder aprovechar las máximas posibilidades de rendimiento es necesario conocer la arquitectura de las unidades de procesamiento gráfico y así como los cuellos de botella que potencialmente puedan perjudicar a la optimización de nuestro algoritmo.

Aunque otras arquitecturas gráficas puedan ser similares en muchos aspectos, describiremos los conceptos básicos de la arquitectura CUDA, que es la que hemos utilizado para paralelizar los cálculos de estado de las redes neuronales y que fue diseñada explícitamente para soportar GPGPU incluso desde lenguajes de alto nivel. En principio C, pero luego también otros leguajes como FORTRAN, C++ y OpenCL. Desde la serie NVIDIA GeForce 8000 todas las gráficas que ha producido NVIDIA obedecen a la arquitectura básica CUDA (excepto las específicas para dispositivos móviles, que siguen la aruitectura Tegra). Aunque tarjetas posteriores ofrecen nuevas capacidades y posibilidades de ajuste de los algoritmos, son retrocompatibles con respecto al código implementado para versiones anteriores.

*** DONE Modelo de programación
#+LaTeX: \label{disenoParalCUDAprog}

C para CUDA es una extensión de C que permite al programador difinir funciones, llamadas núcleos (kernels) que cuando son llamadas se ejecutan N veces por N hilos CUDA diferentes, en vez de una sola vez como las funciones C habituales. Para definir un kernel se usa el especificador de declaración =__global__= y el número de hilos CUDA para cada llamada se especifica con la nueva sintaxis ~<<<...>>>~ del siguiente ejemplo:

#+begin_src c
// Definicion del Nucleo
__global__ void MiKernel(float* A, float* B, float* C)
{
    ...
}
int main()
{
    ...
    // Invocacion del Nucleo
    MiKernel<<<1, N>>>(A, B, C);
}
#+end_src

A cada uno de los hilos que ejecuta el kernel se le da un identificador de hilo único que es accesible desde el kernel con la variable interna threadIdx. El siguiente código de ejemplo suma dos vectores A y B de tamaño N y guarda el resultado en el vector C:

#+begin_src c
// Definicion del Nucleo
__global__ void SumaVectores(float* A, float* B, float* C)
{
    int i = threadIdx.x;
    C[i] = A[i] + B[i];
}
int main()
{
    ...
    // Invocacion del Nucleo
    SumaVectores<<<1, N>>>(A, B, C);
}
#+end_src

Cada uno de los hilos que ejecuta SumaVectores() realiza la suma de un par de elementos diferente.

Por conveniencia, threadIdx es un vector de tres componenetes para que los hilos puedan ser identificados usando un índice de una, dos o tres dimensiones, formando bloques de hilos unidimensionales, bidimensioneales o tridimensionales. Como ejemplo, el siguiente código suma los elementos de las matrices A y B de tamaño NxN y almacena el resultado en la matriz C:

#+begin_src c
// Definicion del Nucleo
__global__ void SumarMatriz(float A[N][N], float B[N][N], float C[N][N])
{
    int i = threadIdx.x;
    int j = threadIdx.y;
    C[i][j] = A[i][j] + B[i][j];
}
int main()
{
    ...
    // Invocacion del Nucleo
    dim3 dimBlock(N, N);
    SumarMatriz<<<1, dimBlock>>>(A, B, C);
}
#+end_src

El índice del hilo y su ID se relacionan de manera directa: para un bloque unidimensional, son iguales; para un bloque bidimensional de tamaño (Dx, Dy), el ID del hilo en con índice (x, y) es (x + y Dx); para uno tridimensional de tamaño (Dx, Dy, Dz), el ID del hilo con índice (x, y, z) es (x + y Dx + z Dx Dy).

Los hilos dentro de un mismo bloque pueden cooperar entre ellos compartiendo datos a través de la memoria compartida y sincronizando su ejecución para coordinar el acceso a memoria. Para ser más precisos, uno puede especificar puntos de sincronización en el núcleo llamando a la función interna =__syncthreads()= que actua como una barrera que hace esperar a todos los hilos del bloque antes de que ninguno pueda seguir. 

Para una cooperación eficiente, se espera que la memoria compartida sea de baja latencia y cercana al núcleo del procesador, como una caché de primer nivel, también que =__syncthreads()= sea ligera y todos los hilos de un bloque deben estar en el mismo núcleo de procesamiento. Por ello el número de hilos por bloque está restringido por los recursos limitados de memoria de un núcleo de procesamiento. En GPUs actuales un bloque de hilos puede contener hasta 512 hilos.

Sin embargo, un kernel puede ser ejecutado por múltiples bloques de hilos similares, de forma que el número total de hilos sea igual al número de hilos por bloque multiplicado por el número de bloques. Estos múltiples bloques se organizan en grids unidimensionales o bidimensionales de bloques de hilos como se muestra en la figura \ref{cudaGridThreadBlocks}. 

#+LaTeX: \label{figGridThreadBlocks}
TODO figGridThreadBlocks

La dimensiones del grid se especifica con el primer parámetro específico del kernel entre la sintaxis ~<<<...>>>~. Cada bloque dentro del grid se puede identicar con un índice unidimensional o bidimensional a través de la variable interna blockIdx. Las dimensiones de el bloque de hilos es accesible desde el kernel usando la variable interna blockDim. El código de ejemplo anterior quedaría así:

#+begin_src c
// Definicion del Nucleo
__global__ void SumarMatriz(float A[N][N], float B[N][N], float C[N][N])
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i < N && j < N)
        C[i][j] = A[i][j] + B[i][j];
}
int main()
{
    ...
    // Invocacion del Nucleo
    dim3 dimBlock(16, 16);
    dim3 dimGrid((N + dimBlock.x – 1) / dimBlock.x,
                 (N + dimBlock.y – 1) / dimBlock.y);
    SumarMatriz<<<dimGrid, dimBlock>>>(A, B, C);
}
#+end_src

El bloque de tamaño 16x16 = 256 se ha cogido algo arbitrariamente, y el grid se crea con suficientes bloques para tener un hilo por elemento de la matriz como antes. 

Los bloques de hilos deben poder ejecutarse independientemente, en cualquier orden, en paralelo o en serie. Este requerimiento de independencia hace que los bloques de hilos se puedan planificar en cualquier orden en cualquier número de núcleos, permitiendo a los programadores escribir código que escala para cualquier número de núcleos. El número de bloques en un grid es típicamente dictado por el tamaño de los datos a procesar en lugar del número de procesadores en el sistema, al que puede superar ampliamente.

Además de la jerarquía para la organización de los hilos descrita existe una jerarquía de memorias a cuyos diferentes espacios pueden acceder los hilos CUDA como muestra la figura \ref{cudaMemory}. Cada hilo tiene una memoria privada local. Cada bloque de hilos tiene uuna memoria compartida visible para todos los hilos del bloque y cuyos datos se mantienen por lo que dure el procesamiento del bloque. Finalmente, todos los hilos de todos los bloques tienen acceso a la misma memoria global. 

#+LaTeX: \label{cudaMemory}
TODO cudaMemory

También hay dos espacios de memoria adicionales de sólo lectura que accesibles por todos los hilos: los espacios de memoria constantes y texturas. La memoria global, la de constantes y la de texturas pueden ser optimizadas para diferentes usos de memoria y son consistentes entre llamadas a kernels de la misma aplicación.

El modelo de programación CUDA asume que los hilos se ejecutarán en un dispositivo físicamente separado que opera como coprocesador de un programa C anfitrión. Los kernels se ejecutan en la GPU y el resto del programa C se ejecuta en una CPU anfitrión. También asume que tanto el anfitrión como el dispositivo mantienen su propia DRAM, llamadas memoria anfitrión y memoria de dispositivo, respectivamente.

Por tanto, un programa gestiona los espacios de memoria global, de constantes y de texturas visibles a los kernels a través de llamadas a la librería CUDA runtime. Esto incluye reserva, liberación de memoria y transferencia entre las memorias anfitrión y de dispositivo.

Ademas, se puede hacer un sistema anfitrión con varias GPUs y hacer llamadas de kernels con diferentes datos y configuraciones a cada uno de los dispoitivos. En el presente proyecto, sin embargo, se prescinde de esa posibilidad, así como de usar las memorias de constantes y de texturas.

*** DONE Arquitectura CUDA
#+LaTeX: \label{disenoParalCUDAarq}

La arquitectura CUDA se construye alrededor de un conjunto escalable de Multiprocesadoes de flujo (Streaming Multiprocessors, SMs). Cuando un programa CUDA en la CPU anfitrión invoca a un grid de kernel, los bloques del grid son enumerados y destribuidos a los multiprocesadores con capacidad de ejecución (TODO? como se muestra en la figura 4-1). Los hilos de un bloque se ejecutan concurrentemente en un mismo multiprocesador. Cuando los bloques terminan, nuevos bloques son lanzados en los Multiprocesadores que queden libres.

Un multiprocesador consta de 8 núcleos que son procesadores escalares (Scalar Processors, SP), dos uunidades de función especial para trascendentales, una unidad de intrucciones multi-hilo, y una memoria compartida interna. El multiprocesador crea, gestiona y ejecuta los hilos concurrentes en un hardware con sobrecarga de planificación de ejecución nula. Implementa la barrera de sincronización intrínseca =__syncthreads()= con una sola instrucción. La rápida barrera de sincronización junto con la ligera creación de hilos y la sobrecarga nula de planificación soporta eficientemente un paralelismo muy granulado, permitiendo, por ejemplo, una descomposición con baja granulidad de problemas asignando un hilo a cada elemento de datos (como un pixel en una imagen, una celda en un calculo basado en una rejilla [grid] o una neurona de salida en una capa de una red neuronal).

Para gestionar cientos de hilos corriendo varios programas diferentes, el multiprocesador emplea una nueva arquitectura llamada SIMT (Single-instruction, multiple-trhead; una instrucción, múltiples hilos). El multiprocesador mapea cada hilo en un núcleo de procesamiento escalar, y cada hilo escalar se ejecuta independientemente con su propia dirección de instrucción y registro de estado. El multiprocesador SIMT crea, gestiona, planifica y ejecuta hilos en grupos de 32 hilos paralelos llamados warps (Termino originado en Weaving, la primera tecnología de hilos paralelos). Los hilos individuales que componene un warp SIMT empiezan juntos en la misma dirección de programa, pero son libres de divergir y seguir una ejecución independiente.

Cuando un multiprocesador recibe uno o más bloques de hilos para ejecutar, los divide en warps que son programados por la unidad SIMT. El modo en que un bloque es dividido en warps es siempre el mismo; cada warp contiene hilos con IDs consecutivos y crecientes con el primer warp conteniendo el hilo 0. 

Por cada tiempo de ejecución de intrucción, la unidad SIMT selecciona un warp que esté preparado para ser ehecutado y les da la siguiente instrucción a los hilos activos del warp. El warp ejecuta una instrucción común cada vez, por lo que la máxima eficiencia se alcanza cuando los 32 hilos del warp siguen el mismo flujo de ejecución. Si los hilos que divergen debido a una bifurcación condicional dependiente de los datos, el warp ejecuta de forma seliarizada cada camino de ejecución, desactivando los hilos que no están en ese camuno. Cuando todos los caminos se completan, los hilos convergen de nuevo en el mismo flujo de ejecución. Estas bifucaciones ocurren sólo dentro de un mismo warp; los diferentes warps se ejecutan independientemente sin importar si estos están ejecutando caminos de código comunes o disjuntos.

La qrquitectura SIMT se parece a las organizaciones vectoriales SIMD (Single Instruction, Multiple Data) en que una sola instrucción controla multiples elementos de procesamiento. Una diferencia clave entre es que las arquitecturas vectoriales SIMD exponen el tamaño del vector SIMD al software, mientras que las instrucciones SIMT especifican la ejecución y el comportamiento de las bifurcaciones para un solo hilo. A diferencia de las maquinas vectoriales SIMD, SIMT permite a los programadores escribir código a nivel de hilo para hilos independientes y escalares, así como código con paralelismo de datos para hilos coordinados. En lo que se refiere a la corrección del código, el programador puede basicamente ignorar el comportamiento SIMT; sin embargo, se pueden conseguir mejoras de rendimiento sustanciales teniendo en cuenta que el código puede hacer que los hilos de un warp se bifurquen y evitándolo en la medida de lo posible. En la práctica, esto es similar al rol de las lineas de cache en el código tradicional: el tamaño de las lineas de cache se puede ignorar de forma segura cuando se diseña para que el código sea correcto pero debe ser considerado en la estructura del código cuando se diseña para un rendimiento máximo. Las arquitecturas vectoriales, sin embargo, requieren que el software haga las cargas coalescentes y gestione las divergencias manualmente.

Como se muestra en la figura \ref{arqCUDAdetalle}, cada mutliprocesador tiene memoria interna de 4 tipos:

- Un conjunto de registros locales de 32 bits por procesador.
- Una cache de datos paralelos o memoria compartida que es compartida por todos los procesadores escalares.
- Una cache de constantes de sólo lectura que es compartida por todos los procesadores escalares y acelera las lecturas desde el espacio de memoria de constantes, que es una región de sólo lectura de la memoria del dispositivo.
- Una cache de texturas de sólo lectura que es compartida por todos los procesadores escalares y acelera las lecturas desde el espacio de memoria de texturas, que es una región de sólo lectura de la memoria del dispositivo; cada multiprocesador accede a la cache de texturas a través de la unidedad de texturas que implementa los diferentes modos de direccionamiento y filtrado de datos especiales para texturas.

#+LaTeX: \label{arqCUDAdetalle}
TODO arqCUDAdetalle

Los espacios de memoria locales y globales son regiones de lectura/escritura de la momoria del dispositivo y no son cacheados. 
El número de bloques que un multiprocesador puede procesar a la vez - lo que se denomina como número de bloques activos por multiprocesador - depende de cuantos registros por hilo y cuánta memoria compartida por bloque son necesarios para un kernel dado, debido a que los registros de un multiprocesador y la momoria compartida son divididos entre todos los hilos de los bloques activos. Si no hay suficientes registros o memoria compartida disponibles por multiprocesador para procesar al menos un bloque, el kernel no podrá ser lanzado. El número máximo de bloques activos por multiprocesador, así como él número máximo de warps activos y el número de hilos activos dependen del dispositivo CUDA concreto.

Si una instrucción no atómica ejecutada en un warp escribe en la misma localización global de momoria compartida para más de un hilo dentro de warp, el número de escrituras serializadas que suceden en esa localización y el orden en que ocurren no está definido, pero se garantiza que al menos una de las escrituras se realizará. Si una instrucción atómica ejecutada por un warp lee, modifica o escribe sobre la misma localización en momodia global para más de uno de los hilos del warp, todas las lecturas, modificaciones y escrituras sobre esa localización se realizan y son todas serializadas, epro el orden en que ocurren tampoco está definido.

*** TODO Reducción paralelizada
#+LaTeX: \label{disenoParalCUDAreduc}

La primera aproximación para la implementación de nuestro algoritmo genérico de cálculo de estado de una capa de red neuronal sobre la arquitectura CUDA estaba claramente influída por la optimización SSE2 anterior. Aquella función de ensamblador calculaba el resultado para una neurona de salida. En este primer kernel CUDA haremos lo mismo: cada llamada al kernel nos servirá para calcular la salida de un neurona (de nuevo, dejando la función de activación aparte). De este modo, cada hilo hará una multiplicación entre una entrada y un peso y luego se sumarán todos los resultados usando una reducción paralela.

En la sección \ref{disenoParalXMMbyte} utilizamos una instrucción especial para hacer la reducción y poder sumar los 16 elementos de un bloque, pero no existe una instrucción similar en CUDA. En \ref{disenoParalXMMfloat} se acumulaban los resultados en un registro con cuatro floats que se sumaban al final. El modo en que se sumaban no era lo que más aceleraba al algortimo, pero nos da una pista de lo que debemos hacer. Primero se sumaban dos y dos en una sóla instrucción (tras dduplicar el registro y desplazarlo) y después los otros dos resultantes. Generalizando a cualquier número de elementos iniciales y sumando los elementos de dos en dos de forma paralela, vemos que lo que tenemos que usar es una reducción en árbol\cite[Harris2007]{Harris2007}.

SEGUIR

*** TODO Paralelizar las salidas
#+LaTeX: \label{disenoParalCUDAsal}
*** TODO Matriz de pesos invertida
#+LaTeX: \label{disenoParalCUDAinv}
* TODO [0/3] Manual del programador
#+LaTeX: \label{manualProgr}
** TODO Guia de instalación
#+LaTeX: \label{manualProgrInstal}

sudo aptitude install make g++ nasm gnuplot
sudo aptitude install texlive-latex-recommended texlive-latex-extra

** TODO Uso general (API)
#+LaTeX: \label{manualProgrApi}
** TODO Extensibilidad a partir de interfaces
#+LaTeX: \label{manualProgrInterf}
\newpage
* TODO [2/3] Experimentaci\'on
#+LaTeX: \label{experimentacion}

En esta sección se describen los problemas para los que se entrenarán las redes neuronales y las utilidades implementadas para la experimentación.

** DONE Tareas de clasificaci\'on
#+LaTeX: \label{experimentacionClasif}

Las tareas de clasificación son una aplicación común de las redes neuronales entrenadas con retropropagación del error. También podemos entrenar nuestras redes neuronales para aprender a desempeñar este tipo de tares utilizando algoritmos genéticos. En general, la clasificación consiste en agrupar conjuntos de entradas posibles en clases. Por ejemplo, las entradas {e1, e3, e5} pentenecen a la clase c1; las entradas {e2, e4} pertenecen a la clase c2; las {e6, e7} a la clase c3, etc. Cada entrada sólo puede pertenecer a una clase. La clasificación tiene muchas aplicaciones el como reconocimiento de patrones o la construcción de filtros.

Las tareas de clasificación que se han elegido son simples. Se trata de operaciones lógicas entre dos vectores binarios. Las operaciones escogidas son AND (Y lógico), OR (O lógico) y XOR (O lógico exclusivo). Es sabido que para poder desempeñar la tarea XOR son necesarias redes neuronales de más de una capa, es decir, con capas ocultas. Si bien AND y OR eran tareas que un perceptrón simple (red neuronal de una sola capa) podía aprender, no puede aprender, sin embargo la tarea XOR. Esta última tarea fué la primera para la que se entrenó un perceptrón multicapa utilizando el algortimo de retropropagación del error y se ha convertido en un Benchmark común para algunos algortimos de aprendizaje artificial [TODO referencia bilbiográfica].

Puede parecer poco intuitivo que el cálculo de estas operaciones lógicas constituyan una tarea de clasificación, por lo que pondremos unos ejemplos ilustrativos. A continuación se muestran las clasificaciones para las tareas AND, OR y XOR para vectores de un tamaño de 1 bit. Las entradas, por tanto, son dos vectores de 1 bit (v1 y v2). Como la salida será de un bit, en estos casos sólo existen dos clases (0 ó 1) para cada operación/clasificación.

| v1 | v2 | Clase (OR) | Clase (AND) | Clase (XOR) |
|----+----+------------+-------------+-------------|
|  0 |  0 |          0 |           0 |           0 |
|  1 |  0 |          1 |           0 |           1 |
|  0 |  1 |          1 |           0 |           1 |
|  1 |  1 |          1 |           1 |           0 |

Expresado de otra forma, si llamamos c0 a la clase 0 y c1 a la clase 1, para la clasificación OR la entrada {00} pertenece a c0 y las entradas {10, 01, 11} pertenecen a c1; para AND, {00, 10, 01} pertenecen a c0 y {11} a c1; para XOR {00, 11} pertenecen a c0 y {10, 01} pertenecen a c1.

Como se describió en el capítulo \ref{manualProgrInterf}, para que nuestro sistema pueda aprender una tarea nueva, sólo es necesario implementar una clase que herede de la interzaz Task, en este caso, la clase implementada es BinaryTask. El método más importante es test, que toma un individuo como parámetro, lo prueba y le asigna el fitness resultante. También es importante el método setInputs, con el que se conectan las variables internas de la tarea con las entradas de la red neuronal de un individuo. Por último, getExample devuelve un individuo construido cuya estructura es suficiente para aprender la tarea concreta para la que se quiere entrenar a la población.

La clase BinaryTask es bastante flexible respecto a cómo puede ser inicializada. Hay dos parámetros que son olbigatorios: un enumerado BinaryOperation que indica que tipo de operación será realizada (BO_OR, BO_AND ó BO_XOR) y el tamaño de los vectores de entrada, que es igual al tamaño del de salida.
Existe un tercer parámetro optativo numTests que hace referencia al número de pruebas para evaluar a un individuo. Si no se rellena, se probarán todas las combinaciones posibles entre los dos vectores de entrada; si se rellena, determinará el número de pruebas aleatorias que se realizarán para probar a cada individuo. Para las dos posibilidades, el individuo empieza con una puntuación igual al número de diferencias con las salidas esperadas que podría obtener cómo máximo y se irán restando las diferencias que se vayan encontrando. Así, la puntuación del inndividuo será mejor cuanto menor sea el número de diferencias sigueindo la siguiente fórmula: Fitness = Número máximo de diferencias posibles - número de diferencias obtenidas.
Las pruebas aleatorias consisten simplemente en dar valores aleatorios a los vectores, hacer que la red neuronal obtenga su salida, obtener la salida deseada realizando la operación lógica correspondiente y comparar las diferencias.

No rellenar el número de pruebas y dejar que se evalúen todas las posibilidades nos dará valores de fitness más precisos, pero puede hacer las pruebas muy lentas para tamaños de vectores más grandes.

Para que esta tarea pueda ser realizada por neuronas binarias, bipolares y reales, en lugar de comparar la salida de la neurona directamente con la salida deseada se usarán aproximaciones. Se entenderá que en la salida de las redes neuronales, cualquier valor mayor o igual a 0.5 es equivalente a un 1 y cualquier valor menor que 0.5 (por ejemplo -1 para una neurona bipolar; 0.1 ó -7 para una neurona real) es equivalente a un 0. Esto se podría implementar con una capa adicional, pero se ha preferido por simplicidad hacerlo directamente dentro de la clase BinaryTask.

** DONE Juegos de estrategia abstractos
#+LaTeX: \label{experimentacionJuegos}

En la sección anterior \ref{experimentacionClasif} hemos visto ejemplos de tareas para las que se podían entrenar redes neuronales con el método tradicional de retropropagación del error. En esta sección nos dedicaremos a una tarea para la que no es tan fácil conocer las salidas deseadas. Los juegos de estrategia abstractos[fn:juegEstratAbst] son aquellos juegos de estrategia para los que se trata de minimizar el factor suerte y que carecen de trasfondo o ambientación. Casi todos entran dentro de las categorías de tablero, cartas o piezas (como el dominó). No tienen información oculta ni elementos no determinísticos y frecuentemente se juegan por dos jugadores en turnos alternativos.

Nos hemos centrado en los juegos de tablero y en concreto en el juego conocido como Othello o Reversi. Otros juegos de estrategía abstractos de tablero podrían ser las damas, el tres en raya, el ajedrez, el go, el arimaa, etc. El tres en raya y las damas, por ejemplo, son problemas completamente resueltos matemáticamente y en esos casos sí sería relativamente fácil emparejar todas las posibles entradas con sus salidas deseadas para poder así entrenar a una red neuronal mediante retropropagación, pero no son particularmente interesantes desde el punto de vista del aprendizaje artificial. En otros juegos, los algoritmos de poda alfa-beta con alguna heurística diseñada por expertos y ejecutados en computadores son ampliamente superiores a los jugadores profesionales de los mismos. Es el caso del Reversi y el ajedrez.

En otros juegos, el árbol de posibilidades crece tanto con cada nivel que la ventaja de una mayor lectura en profundidad que disfrutan las máquinas se desvanece y la intuición humana aún es superior al cálculo computacional, por increíble que pueda parecer. El juego del Go (cercado), a pesar de tener un tablero tan simple como el del Reversi y pocas reglas simples de enumerar entra en esta categoría. Es un juego asiático más antiguo que el ajedrez y muy célebre en oriente, en especial en China (weiqui), Korea (baduk) y Japón (igo). Por el momento, la mejor de las máquinas (que no usa poda alfa-beta sino métodos probabilísticos y altamente paralelizables como el algortimo de Monte Carlo\cite[Chaslot2010]{Chaslot2010}) no es capaz de ganar al peor de los jugadores profesionales.

El Arimaa es un juego diseñado recientemente con el objetivo específico de que los algoritmos habituales de búsqueda en profundidad no fuesen efectivos  \cite[Syed03]{Syed03}. Es parecido al ajedrez, con el mismo tablero y piezas, pero sin una configuración inicial preestablecida, con casillas especiales, turnos de dos pasos independientes, movimientos de cambiar de posición una pieza con la del contrario, etc.

Aunque nuestras redes también pueden ser entrenadas para dar una heurística para juegos como el Ajedrez y el Arimaa, hemos preferido optar por los juegos más simples de implementar con piezas de un sólo tipo (el Reversi y el Go), pues esto permitirá reutilizar más código y también puede ser interesante éstudiar el aprendizaje de redes bipolares en este tipo de juegos. Se ha  implementado un tablero que serviría para ambos juegos, pero sólo se ha implementado la tarea Reversi. Para la terea Go, extremadamente interesante, se recomienda utilizar algún jugador ya implementado mediante software libre como puede ser GnuGo o FueGo.

Este tipo de tareas se implementará de forma general haciendo que las redes neuronales actúen como una heurística. Esta heurística puede ser usada como la base de un algoritmo de poda alfa-beta con profundidad configurable o simplemente considerando solamente el conjunto de todos los movimientos legales inmediatos, que es lo que se ha hecho para el caso Reversi. Para evaluar las redes neuronales, en lugar de enfrentarlas entre sí, se ha preferido utilizar un adversario también automático pero no basado en redes neuronales. Así, cada red que quiera ser evaluada se enfrenta a este jugador una o varias veces y se acumulan los resultados para obtener el fitness.

El jugador que se ha implementado para Reversi es extremadamente simple, pero, aún así, es capáz de ganar al jugador humano casual. No utiliza poda  alfa-beta, sino simplemente evalua todos los movimientos legales inmediatos y elige el mejor, igual que lo harán los jugadores neuronales. La diferencia es que el oponente no utiliza una red neuronal como heurística. La heurística del oponente consiste simplemente en contar la puntuación que resultaría si se realizase un movimiento concreto, como si la partida acabase en ese momento. El oponente, por tanto, tiene acceso a la puntuación actual de cada movimiento hipotético y en eso basa su heurística. La red neuronal, sin embargo, no tiene acceso a esas puntuaciones: solamente toma como entrada el tablero resultante de cada movimiento hipotético y debe con eso dar una aproximación de lo bueno que es el movimiento. Para poder ganar a nuestro oponente tendrá que ser capáz, por lo menos, de ser capaz de calcular la puntuación de forma similar a su oponente. No obstante, la red neuronal actúa como una caja negra y no sabemos realmente en qué criterios internos se está basando. Lo que sí se podría hacer es construir un circuito lógico equivalente a la red neuronal para analizarlo y tratar de extraer conclusiones sobre la estrategia aprendida.

La tarea Reversi se implementa en la clase ReversiTask que también hereda de la clase abstracta Task y que utiliza la clase ReversiBoard que implementa las reglas de juego de Reversi y que, a su vez, hereda de la clase que implementa el el tablero genérico para juegos con piezas iguales pero de dos jugadores Board. Éste último siempre es de un tamaño cuadrado (las mismas casillas a lo largo que a lo ancho) pero el tablero de Reversi tiene, además, la restricción de ser como mínimo de un tamaño 4x4. Esto es así por que las cuatro piezas centrales (2x2) empiezan ya rellenas para que los juegadores tengan movimientos legales al inicio.

TODO ¿debo explicar las reglas del juego?

** TODO Utilidades para la experimentación
#+LaTeX: \label{experimentacionUtil}
* TODO Resultados: Rendimiento
#+LaTeX: \label{rendimiento}
En esta sección se analizan resultados de rendimiento en tiempo de ejecución.
** Rendimiento de las implementaciones paralelas de red neuronal
#+LaTeX: \label{rendImpl}

En esta sección se presentan los resultados en tiempo de ejecución de los métodos que se ejecutan de forma diferente con cada implementación.

*** Acumulación de resultados
#+LaTeX: \label{rendImplAcumul}

En la figura \ref{grafImplCalculate}, puede apreciarse que la implementación con instrucciones SSE2 de ensamblador para utilizar el coprocesador XMM es muy superior a la implementación de referencia en lenguaje C, especialmente para los tipos de Buffer BIT y SIGN.

#+CAPTION:    Método de acumulación de resultados (Connection::calculateAndAdd).
#+LABEL:      grafImplCalculate
#+ATTR_LaTeX: width=\textwidth
[[./img/Connection_calculateAndAddTo.png]]
\newpage

*** Activación

De la figura \ref{grafImplActivation} se extraen varias conclusiones. No mucha diferencia de rendimiento entre las implementaciones y prácticamente ninguna cuando las neuronas son de tipo FLOAT. Esto era de esperar porque ambas implementaciones son idénticas: no se han hecho optimizaciones SSE2 para la función de activación y para el tipo FLOAT el algoritmo es idéntico al de C.

Para los tipos BIT y SIGN, la implementación en C es ligeramente más rápida que para el tipo FLOAT y la  escrita en SSE2 es ligeremante más lenta que la FLOAT. En la implementación SSE2 de BIT y SIGN no se almacenan los bits en el orden normal, si no en la representación especial de SSE2, para que el método de acumulación de resultados pueda ser óptimo.

#+CAPTION:    Método que ejecuta la función de activación para las salidas de una capa (Connection::activation).
#+LABEL:      grafImplActivation
#+ATTR_LaTeX: width=\textwidth
[[./img/Connection_activation.png]]
\newpage

*** Funciones de activación

Si en la figura \ref{grafImplActivation} se comparaba el rendimiento de los distintos tipos de neurona (BIT, SIGN y FLOAT con la función de activación IDENTITY), en la figura \ref{grafImplActivationFunc} se comparan los rendimientos de los distintos tipos de funciones para el tipo de neurona FLOAT. Con el tipo de neurona BIT, la función de activación siempre es BINARY_STEP y con el tipo SIGN la activación siempre es BIPOLAR_STEP, por ello podemos excluir estos tipos de esta gráfica. Además, la implementación SSE2 de la activación para FLOAT es idéntica a la de C, por lo que tampoco se muestran los resultados de la activación SSE2 en este caso.

Se puede ver como, en general, la función más lenta es la sigmoide, seguida de la sigmoide bipolar. La tangente hiperbólica sólo es ligeramente más lenta que el resto, cuyo rendimiento es similar al de la función identidad (que no hace nada).

#+CAPTION:    Método que ejecuta la función de activación para las salidas de una capa (Connection::activation) con tipo de Buffer FLOAT y las diferentes funciones de activación implementadas.
#+LABEL:      grafImplActivationFunc
#+ATTR_LaTeX: width=\textwidth
[[./img/Activation_functions.png]]
\newpage
*** Cruza

No hay una diferencia sustancial de rendimiento entre las diferentes implementaciones y tipos de neuronas para el operador genético de crossover, como se muestra en la figura \ref{grafImplCrossover}. Como en el método de activación, la cruza de SSE2 se ve ligeramente penalizada. En este caso se debe al almacenamiento especial de los pesos para SSE2, que usa bloques de pesos en vez de pesos individuales. La penalización es ligeramente superior para FLOAT.

#+CAPTION:    Método que implementa el operador de crossover para dos conexiones dadas (Connection::crossover).
#+LABEL:      grafImplCrossover
#+ATTR_LaTeX: width=\textwidth
[[./img/Connection_crossover.png]]
\newpage

*** Mutación

De la figura \ref{grafImplMutation} se puede deducir que el operador de mutación tiene un coste mínimo y constante respecto al tamaño de la conexión para todas las implementaciones.

#+CAPTION:    Método que implementa el operador genético de mutación (Connection::mutate).
#+LABEL:      grafImplMutation
#+ATTR_LaTeX: width=\textwidth
[[./img/Connection_mutate.png]]
\newpage

*** Olvido

De manera similar a la operación de mutación, el olvido (figura \ref{grafImplReset}) tiene un coste constante y mínimo.

#+CAPTION:    Método que implementa el operador genético de olvido (Connection::reset).
#+LABEL:      grafImplReset
#+ATTR_LaTeX: width=\textwidth
[[./img/Connection_reset.png]]
\newpage

*** Copiar desde y hacia Interfaz

Estos métodos se usan para recibir entradas y sacar salidas al exterior de la red. Las interfaces sirven para independizar la red de la implementación concreta escogida. Cada implementación debe mapear correctamente desde la representación genérica (Interfaz) hacia su propia representación interna (figura \ref{grafImplCopyFrom}) de los datos y viversa (figura \ref{grafImplCopyTo}).

#+CAPTION:    Método que implementa la copia a un Buffer con una implementación determinada desde un Buffer genérico de la clase Interfaz (Buffer::copyFromInterface).
#+LABEL:      grafImplCopyFrom
#+ATTR_LaTeX: width=\textwidth
[[./img/Buffer_copyFromInterface.png]]

En ambos casos se observa que el coste es muy pequeño excepto para la implementación SSE2 de los tipos BIT y SIGN, por razones similares a las de Activación.

#+CAPTION:    Método que implementa la copia de un Buffer con una implementación determinada a un Buffer genérico de la clase Interfaz (Buffer::copyToInterface).
#+LABEL:      grafImplCopyTo
#+ATTR_LaTeX: width=\textwidth
[[./img/Buffer_copyToInterface.png]]
\newpage

** Rendimiento de los diferentes operadores genéticos
#+LaTeX: \label{rendOperadores}

En esta sección se cronometran los operadores genéticos. Algunos ya se habían analizado en la sección \ref{rendImpl}, pero a un nivel más bajo, del que dependen las implementaciones. Ahora lo que nos interesa es principalmente el coste de los operadores dependiendo de las diferentes formas de usarlo a más alto nivel. Nos abstraemos por ello de la implementación concreta y usamos la implementación SSE2 para todas estas pruebas.

*** Selección

figura \ref{rendGenSelect}

Aunque no se aprecia bien en la figura \ref{rendGenSelect}, las selecciones de ruleta y truncado tienen un coste mínimo y bastante independiente tanto del tamaño total de la población como del número de individuos a seleccionar en comparación con los otros dos esquemas de selección. La selección por ranking es la más costosa y además la que más depende del tamaño total de la población. La selección por torneo es algo menos costosa y depende más del tamaño del torneo que del tamaño total de la población.

#+CAPTION:    Rendimiento de los distintos operadores de selección en función del número de individuos a seleccionar. Cada operador se prueba con tamaños totales de población 400 y 500. Además, para la selección por torneo se muestran los resultados con varios tamaños de torneo.
#+LABEL:      rendGenSelect
#+ATTR_LaTeX: width=\textwidth
[[./img/Population_Selection.png]]
\newpage

*** Cruza

figura \ref{rendGenCruza}

Como muestra la figura \ref{rendGenCruza} el nivel de cruza más costoso es el propio peso, el más barato es el nivel de capa completa y los niveles de neurona tienen rendimientos intermedios y parecidos independientemente de cómo se interprete qué pesos pertenecen a una neurona (si los pesos de entrada a la neurona o los pesos de salida de la misma).

En general, parece que el cruce uniforme es más costoso que el multi-punto y también es más costoso cuanto más se acerque al 50\% la probabilidad de coger el peso de un padre o de otro. El algoritmo multi-punto, sin embargo, no presenta diferencias de rendimiento significativas para 1 punto o 6 puntos de corte.

#+CAPTION:    Rendimiento de los distintos operadores genéticos de cruza en función del tamaño de las capas de neuronas internas.
#+LABEL:      rendGenCruza
#+ATTR_LaTeX: width=\textwidth
[[./img/Individual_crossover.png]]
\newpage

*** Mutación

Según la figura \ref{rendGenMutation}, ambos tipos de mutación son más costosos cuánto mayor es la probabilidad, tal y cómo era de esperar, pues más mutaciones son más escrituras. Además, la mutación probabilística es en general más costosa que la mutación determinística (un número constante de mutaciones por individuo) salvo cuando la probabilidad es muy grande (muchas mutaciones por individuo). Aunque la interfaz determinística es más rápida, también se hace más lenta comprativamente cuanto mayor es la probabilidad. La explicación es que la opción probabilística tiene un coste fijo elevado (un número aleatorio por gen) mientras que en la determinística el coste sube con el número de mutaciones (varios números aleatorios por cada mutación a realizar).

#+CAPTION:    Rendimiento de los distintos operadores genéticos de mutación para diferentes probabilidades. Para el operador no probabilístico, se ha calculado el número de mutaciones por individuo multiplicando la probabilidad por el número de genes (pesos y umbrales), para poder compararlo en igualdad con el operador probabilístico en cuanto al número de escrituras en los pesos.
#+LABEL:      rendGenMutation
#+ATTR_LaTeX: width=\textwidth
[[./img/Individual_mutate.png]]
\newpage

*** Olvido

El nuevo operador de olvido/reset presenta otra vez unos resultados similares a los de la mutación y se pueden extraer conclusiones semejantes como muestra la figura \ref{rendGenOlvido}.

#+CAPTION:    Rendimiento de los distintas interfaces del nuevo operador genético de olvido para diferentes probabilidades. Para el operador no probabilístico, se ha calculado el número de mutaciones por individuo multiplicando la probabilidad por el número de genes (pesos y umbrales), para poder compararlo en igualdad con el operador probabilístico en cuanto al número de escrituras en los pesos.
#+LABEL:      rendGenOlvido
#+ATTR_LaTeX: width=\textwidth
[[./img/Individual_reset.png]]
\newpage

* TODO Resultados: Aprendizaje
#+LaTeX: \label{aprendizaje}
En esta sección se muestran resultados de aprendizaje en términos del mejor fitness de la población en cada generación.
** Comparación entre las distintas funciones de activación
#+LaTeX: \label{aprendFunc}

A continuación observamos cómo influyen las diferentes funciones de activación para las tareas implementadas.

*** OR

Para la tarea Or, no se observan diferencias sustanciales con diferentes funciones de activación al mirar la figura \ref{aprenFuncOr}.

#+CAPTION:    Aprendizaje de la tarea lógica Or con las distintas funciones de activación.
#+LABEL:      aprenFuncOr
#+ATTR_LaTeX: width=\textwidth
[[./img/FunctionTypes_OR.png]]

\newpage
*** AND

Según la gráfica \ref{aprenFuncAnd} la función de activación Sigmoide bipolar es ligeramente superior al resto para la tarea lógica AND.

#+CAPTION:    Aprendizaje de la tarea lógica And las distintas funciones de activación.
#+LABEL:      aprenFuncAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/FunctionTypes_AND.png]]

\newpage
*** XOR

Para la tarea XOR - cuyas redes neuronales tienen 2 capas - la figura \ref{aprenFuncXor} muestra diferencias de en el aprendizaje dependiendo de la función de activación. La función identidad es superior a la mayoría y la de escalón binario inferior. La sigmoide empiza como la mayoría, pero se va haciendo peor según avanza el aprendizaje.

#+CAPTION:    Aprendizaje de la tarea lógica Xor las distintas funciones de activación.
#+LABEL:      aprenFuncXor
#+ATTR_LaTeX: width=\textwidth
[[./img/FunctionTypes_XOR.png]]

\newpage
*** Reversi

Para la tarea Reversi igual que pasaba con la tarea Or, no se observan diferencias sustanciales con diferentes funciones de activación a pesar de que en este caso también se tienen varias capas en la red neuronal (figura \ref{aprenFuncReversi}).

#+CAPTION:    Aprendizaje de la tarea Reversi las distintas funciones de activación.
#+LABEL:      aprenFuncReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/FunctionTypes_REVERSI.png]]

\newpage

** Comparaci\'on entre redes discretas y lineales
#+LaTeX: \label{aprendDiscretLineales}

A continuación compararemos los posibles efectos beneficiosos o perjudiciales al aprendizaje que se pueden obtener a partir de renunciar a las funciones derivables en favor de neuronas de tipo BIT (salida 0 ó 1) ó SIGN (salida -1 ó 1) y de pesos discretos y más reducidos (1 Byte en lugar de los 4 bytes de un float). También se incluyen las funciones de activación BINARY_STEP y BIPOLAR_STEP para FLOAT para ver el caso en que los pesos siguen siendo igual de grandes y las neuronas se comportan como BIT o SIGN (para poder analizar el efecto de los pesos discretos y menores por separado).

*** OR

Para la tarea Or, la función IDENTITY es la mejor opción con muy poca diferencia (figura \ref{aprenDiscretOr}).

#+CAPTION:    Aprendizaje de la tarea lógica Or con los distintos tipos de neuronas (Binarias, bipolares y lineales).
#+LABEL:      aprenDiscretOr
#+ATTR_LaTeX: width=\textwidth
[[./img/BufferTypes_OR.png]]

\newpage
*** AND

Para la tarea And, también con poca diferencia, las funciones bipolares son la opción superior independientemente de si los pesos son almacenados como Floats o cómo Bytes (figura \ref{aprenDiscretAnd}).

#+CAPTION:    Aprendizaje de la tarea lógica And con los distintos tipos de neuronas (Binarias, bipolares y lineales).
#+LABEL:      aprenDiscretAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/BufferTypes_AND.png]]

\newpage
*** XOR

De nuevo observamos más diferencias en la tarea Xor (figura \ref{aprenDiscretXor}). Como en AND, la opciones bipolares son superiores durante todo el aprendizaje. Seguidas de la activación linear, que se va haciendo menos efectiva conforme avanza el aprendizaje, cuando es superada por las versiones binarias. Tanto como para las binarias como para las bipolares, se aprecia una diferencia mínima en favor de las versiones cuyos pesos se alamacenan como floats, pero que no compensan las grandes diferencias de rendimiento comentadas en la sección \ref{rendImplAcumul}.

#+CAPTION:    Aprendizaje de la tarea lógica Xor con los distintos tipos de neuronas (Binarias, bipolares y lineales).
#+LABEL:      aprenDiscretXor
#+ATTR_LaTeX: width=\textwidth
[[./img/BufferTypes_XOR.png]]

\newpage
*** Reversi

Para la tarea Reversi todos los tipos de neuronas obtienen resultados bastante semejantes en la gráfica \ref{aprenDiscretReversi}.

#+CAPTION:    Aprendizaje de la tarea Reversi con los distintos tipos de neuronas (Binarias, bipolares y lineales).
#+LABEL:      aprenDiscretReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/BufferTypes_REVERSI.png]]

\newpage
** Comparaci\'on de operadores gen\'eticos
#+LaTeX: \label{aprendOperGen}

Para estudiar el aprendizaje con los distintos operadores genéticos, se han probado cada una de las 4 tareas implementadas y se han generado gráficas de cada una de ellas por separado. Se ha utilizado un tamaño de población de 8 individuos, de los cuales se seleccionan 4 en cada iteración, que se cruzan, se mutan se prueban los nuevos individuos generados para insertarlos ordenadamente en la población anterior, quedando de nuevo 8. De esta manera, se desechan los 4 peores de entre los 8 que había y los 4 nuevos generados. En caso de empate se favorece a los nuevos, siguiendo el criterio de búsqueda neutral (TODO falta referencia bibliográfica aquí). Cada población utiliza un esquema de selección, cruza y mutación concretos, pero para cada gráfica se hace la media de todos los esquemas posibles (salvo para el operador concreto que se esté estudiando en cada gráfica). El operador de olvido sólo se usa al generar sus propias gráficas, haciendo la media con el todas las posibilidades en el resto de operadores.

*** Selección

Como esquemas de selección se utilizan los operadores de truncado (se selecciona directamente a los mejores), ruleta (con valor base=1), ranking (con valores por defecto base=9 step=6) y torneo (con tamaños de torneo 2 y 4).

**** OR

(figura \ref{aprenSelectOr}).

#+CAPTION:    Aprendizaje de la tarea lógica Or con los distintos esquemas de selección.
#+LABEL:      aprenSelectOr
#+ATTR_LaTeX: width=\textwidth
[[./img/Selection_OR.png]]

\newpage
**** AND

(figura \ref{aprenSelectAnd}).

#+CAPTION:    Aprendizaje de la tarea lógica And con los distintos esquemas de selección.
#+LABEL:      aprenSelectAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/Selection_AND.png]]

\newpage
**** XOR

(figura \ref{aprenSelectXor}). 

#+CAPTION:    Aprendizaje de la tarea lógica Xor con los distintos esquemas de selección.
#+LABEL:      aprenSelectXor
#+ATTR_LaTeX: width=\textwidth
[[./img/Selection_XOR.png]]

\newpage
**** Reversi

 gráfica \ref{aprenSelectReversi}.

#+CAPTION:    Aprendizaje de la tarea Reversi con los distintos esquemas de selección.
#+LABEL:      aprenSelectReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/Selection_REVERSI.png]]


\newpage
*** Cruza

**** OR

(figura \ref{aprenCrossOr}).

#+CAPTION:    Aprendizaje de la tarea lógica Or con los distintos esquemas y niveles de cruza.
#+LABEL:      aprenCrossOr
#+ATTR_LaTeX: width=\textwidth
[[./img/Crossover_OR.png]]

\newpage
**** AND

(figura \ref{aprenCrossAnd}).

#+CAPTION:    Aprendizaje de la tarea lógica And con los distintos esquemas y niveles de cruza.
#+LABEL:      aprenCrossAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/Crossover_AND.png]]

\newpage
**** XOR

(figura \ref{aprenCrossXor}). 

#+CAPTION:    Aprendizaje de la tarea lógica Xor con los distintos esquemas y niveles de cruza.
#+LABEL:      aprenCrossXor
#+ATTR_LaTeX: width=\textwidth
[[./img/Crossover_XOR.png]]

\newpage
**** Reversi

 gráfica \ref{aprenCrossReversi}.

#+CAPTION:    Aprendizaje de la tarea Reversi con los distintos esquemas y niveles de cruza.
#+LABEL:      aprenCrossReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/Crossover_REVERSI.png]]

\newpage
*** Mutación

**** OR

(figura \ref{aprenMutOr}).

#+CAPTION:    Aprendizaje de la tarea lógica Or con los distintos configuraciones de mutación.
#+LABEL:      aprenMutOr
#+ATTR_LaTeX: width=\textwidth
[[./img/Mutations_OR.png]]

\newpage
**** AND

(figura \ref{aprenMutAnd}).

#+CAPTION:    Aprendizaje de la tarea lógica And con los distintos configuraciones de mutación.
#+LABEL:      aprenMutAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/Mutations_AND.png]]

\newpage
**** XOR

(figura \ref{aprenMutXor}). 

#+CAPTION:    Aprendizaje de la tarea lógica Xor con los distintos configuraciones de mutación.
#+LABEL:      aprenMutXor
#+ATTR_LaTeX: width=\textwidth
[[./img/Mutations_XOR.png]]

\newpage
**** Reversi

 gráfica \ref{aprenMutReversi}.

#+CAPTION:    Aprendizaje de la tarea Reversi con los distintos configuraciones de mutación.
#+LABEL:      aprenMutReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/Mutations_REVERSI.png]]

\newpage
*** Operador de olvido

**** OR

(figura \ref{aprenResetOr}).

#+CAPTION:    Aprendizaje de la tarea lógica Or con los distintos configuraciones de olvido (reset).
#+LABEL:      aprenResetOr
#+ATTR_LaTeX: width=\textwidth
[[./img/Reset_OR.png]]

\newpage
**** AND

(figura \ref{aprenResetAnd}).

#+CAPTION:    Aprendizaje de la tarea lógica And con los distintos configuraciones de olvido (reset).
#+LABEL:      aprenResetAnd
#+ATTR_LaTeX: width=\textwidth
[[./img/Reset_AND.png]]

\newpage
**** XOR

(figura \ref{aprenResetXor}). 

#+CAPTION:    Aprendizaje de la tarea lógica Xor con los distintos configuraciones de olvido (reset).
#+LABEL:      aprenResetXor
#+ATTR_LaTeX: width=\textwidth
[[./img/Reset_XOR.png]]

\newpage
**** Reversi

 gráfica \ref{aprenResetReversi}.

#+CAPTION:    Aprendizaje de la tarea Reversi con los distintos configuraciones de olvido (reset).
#+LABEL:      aprenResetReversi
#+ATTR_LaTeX: width=\textwidth
[[./img/Reset_REVERSI.png]]

\newpage
** Comparación de distintos tamaños de población número de individuos conservados por generación

\newpage
* TODO Conclusiones
#+LaTeX: \label{conclusiones}

\newpage

#Bibliografía 
\cleardoublepage\phantomsection
\addcontentsline{toc}{chapter}{\bibname}
\begin{thebibliography}{9}
 
%\cite[texto]{etiqueta}

%
% No he puesto todas las referencias que tenía porque tenía demasiadas y no tengo muy claro qué tengo que hacer cuando unos se citan a otros. 
% Por ejemplo, he dejado muchas citas que Bertona hacía de otros y no sé si eso es correcto. Yao en una sóla frase referencia a muchísima gente y no sé muy bien qué debería hacer.
%Desde luego, he aprendido que la bibliografía es mejor prepararla sobre la marcha que al toda final.
%

\bibitem{Yao99} \textsc{Xin Yao}: \emph{Evolving Artificial Neural Networks}. School of Computer Science, The University of Birmingham (1999).

\bibitem{GomezMiikkulainen2003} \textsc{Faustino J. G\'omez y Risto Miikkulainen}: \emph{Robust Non-Linear Control through Neuroevolution}. Deparment of Computer Science, The University of Texas (2003).

\bibitem{Bertona2005} \textsc{Luis Federico Bertona}: \emph{Entrenamiento de redes neuronales basado en algoritmos evolutivos}. Faculad de ingenier\'ia, Universidad de Buenos Aires (2005).

\bibitem{Harris2007} \textsc{Mark Harris}: \emph{Optimizing Parallel Reduction in CUDA}. NVIDIA Developer Technology, (2007).

\bibitem{Chaslot2010} \textsc{Guillaume Maurice Jean-Bernard Chaslot}: \emph{Monte-Carlo Tree Search}. Tésis doctoral, Universiteit Maastricht, Maastricht, Holanda (2010).

\bibitem{Syed03} \textsc{Syed, Omar; Syed, Aamir}: \emph{Arimaa – a New Game Designed to be Difficult for Computers}. International Computer Games Association Journal (2003).

\end{thebibliography}
* TODO [1/8] Cosas por hacer desperdigadas
- [ ] Poner imagenes en parte CUDA
- [ ] (Teoría: redes neuronales) Explicar la necesidad de funciones de activación continuas para retropropagación
- [ ] (Teoría: redes neuronales) Explicar imposibilidad de recursividad con retropropagación
- [ ] (Teoría: algoritmos genéticos) Introducir a GENITOR con bibliografía
- [ ] (Teoría: algoritmos genéticos/neuro evolución) Introducir representación fregona con bibliografía
- [ ] (Teoría: neuro evolución) NeuroEvolution of Augmenting Topologies (NEAT)
- [ ] (Teoría: neuro evolución) Redes recurrentes, pybrain, Jürgen Schmidhuber
* Footnotes

[fn:cudaSuperComp]
\newline
http://gpgpu.org/2010/11/17/gpus-in-3-of-5-fastest-supercomputers
\newline
http://blogs.nvidia.com/2011/11/gpu-supercomputers-show-exponential-growth-in-top500-list/

[fn:juegEstratAbst]
\newline
http://en.wikipedia.org/wiki/Abstract_strategy_game
